{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "4J5foYsrwrJE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61537ca8-7813-44f1-e777-c3c815cdf9d0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gu-Pnc6Gu_Af",
        "outputId": "c97570d8-756d-40d0-86a4-b0afe1d251a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd drive"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T1_RDMzdUoe1",
        "outputId": "43247365-4554-4f0d-cb8a-ea86031414e4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd MyDrive"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eH5M7kxnUvhQ",
        "outputId": "97123b80-84b8-4182-981d-df7b9eafdf1d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/cszn/KAIR.git"
      ],
      "metadata": {
        "id": "uovUYcZJxIKR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd KAIR"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-Bux7qKwHP0",
        "outputId": "06fbe31a-8bdd-4d5b-9732-d1cdeecf8682"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/KAIR\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H8_ROoEfwfdu",
        "outputId": "f172af8b-5e4c-4f24-f6ba-081d825a8b79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data\t\t\t\t    main_test_face_enhancement.py  main_train_psnr.py\n",
            "DIV2K_train_HR.zip\t\t    main_test_fdncnn.py\t\t   main_train_usrnet.py\n",
            "DIV2K_train_LR_bicubic_X2.zip\t    main_test_ffdnet.py\t\t   main_train_vrt.py\n",
            "DIV2K_train_LR_bicubic_X2.zip.1     main_test_imdn.py\t\t   matlab\n",
            "DIV2K_train_LR_bicubic_X3.zip\t    main_test_ircnn_denoiser.py    models\n",
            "DIV2K_train_LR_bicubic_X4.zip\t    main_test_msrresnet.py\t   model_zoo\n",
            "docs\t\t\t\t    main_test_rrdb.py\t\t   options\n",
            "figs\t\t\t\t    main_test_rvrt.py\t\t   README.md\n",
            "kernels\t\t\t\t    main_test_srmd.py\t\t   requirement.txt\n",
            "LICENSE\t\t\t\t    main_test_swinir.py\t\t   retinaface\n",
            "main_challenge_sr.py\t\t    main_test_usrnet.py\t\t   scripts\n",
            "main_download_pretrained_models.py  main_test_vrt.py\t\t   superresolution\n",
            "main_test_dncnn3_deblocking.py\t    main_train_dncnn.py\t\t   testsets\n",
            "main_test_dncnn.py\t\t    main_train_drunet.py\t   trainsets\n",
            "main_test_dpsr.py\t\t    main_train_gan.py\t\t   utils\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p trainsets/trainH/HR"
      ],
      "metadata": {
        "id": "fgsbGNcZxUvb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p trainsets/trainH/LR_bicubic/X2/"
      ],
      "metadata": {
        "id": "mYEIVBlkxZpg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p trainsets/trainH/LR_bicubic/X3/"
      ],
      "metadata": {
        "id": "wHR_fOyBxdVX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p trainsets/trainH/LR_bicubic/X4/"
      ],
      "metadata": {
        "id": "UNcZWFgtxe3Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download DIV2K training set\n",
        "!wget https://data.vision.ee.ethz.ch/cvl/DIV2K/DIV2K_train_HR.zip\n",
        "!wget https://data.vision.ee.ethz.ch/cvl/DIV2K/DIV2K_train_LR_bicubic_X2.zip\n",
        "!wget https://data.vision.ee.ethz.ch/cvl/DIV2K/DIV2K_train_LR_bicubic_X3.zip\n",
        "!wget https://data.vision.ee.ethz.ch/cvl/DIV2K/DIV2K_train_LR_bicubic_X4.zip\n",
        "\n",
        "# Extract and organize\n",
        "!unzip DIV2K_train_HR.zip -d trainsets/trainH/HR/\n",
        "!unzip DIV2K_train_LR_bicubic_X2.zip -d trainsets/trainH/LR_bicubic/X2/\n",
        "!unzip DIV2K_train_LR_bicubic_X3.zip -d trainsets/trainH/LR_bicubic/X3/\n",
        "!unzip DIV2K_train_LR_bicubic_X4.zip -d trainsets/trainH/LR_bicubic/X4/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "brz2MEIE-ADU",
        "outputId": "4fafbc4e-2227-4b00-9a7c-0e60ffd2aab7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-11-16 07:55:42--  https://data.vision.ee.ethz.ch/cvl/DIV2K/DIV2K_train_HR.zip\n",
            "Resolving data.vision.ee.ethz.ch (data.vision.ee.ethz.ch)... 129.132.52.178, 2001:67c:10ec:36c2::178\n",
            "Connecting to data.vision.ee.ethz.ch (data.vision.ee.ethz.ch)|129.132.52.178|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3530603713 (3.3G) [application/zip]\n",
            "Saving to: ‘DIV2K_train_HR.zip’\n",
            "\n",
            "DIV2K_train_HR.zip  100%[===================>]   3.29G  19.1MB/s    in 3m 4s   \n",
            "\n",
            "2024-11-16 07:58:46 (18.3 MB/s) - ‘DIV2K_train_HR.zip’ saved [3530603713/3530603713]\n",
            "\n",
            "--2024-11-16 07:58:47--  https://data.vision.ee.ethz.ch/cvl/DIV2K/DIV2K_train_LR_bicubic_X2.zip\n",
            "Resolving data.vision.ee.ethz.ch (data.vision.ee.ethz.ch)... 129.132.52.178, 2001:67c:10ec:36c2::178\n",
            "Connecting to data.vision.ee.ethz.ch (data.vision.ee.ethz.ch)|129.132.52.178|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 925390592 (883M) [application/zip]\n",
            "Saving to: ‘DIV2K_train_LR_bicubic_X2.zip’\n",
            "\n",
            "DIV2K_train_LR_bicu 100%[===================>] 882.52M  15.7MB/s    in 61s     \n",
            "\n",
            "2024-11-16 07:59:49 (14.4 MB/s) - ‘DIV2K_train_LR_bicubic_X2.zip’ saved [925390592/925390592]\n",
            "\n",
            "--2024-11-16 07:59:49--  https://data.vision.ee.ethz.ch/cvl/DIV2K/DIV2K_train_LR_bicubic_X3.zip\n",
            "Resolving data.vision.ee.ethz.ch (data.vision.ee.ethz.ch)... 129.132.52.178, 2001:67c:10ec:36c2::178\n",
            "Connecting to data.vision.ee.ethz.ch (data.vision.ee.ethz.ch)|129.132.52.178|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 427847282 (408M) [application/zip]\n",
            "Saving to: ‘DIV2K_train_LR_bicubic_X3.zip’\n",
            "\n",
            "DIV2K_train_LR_bicu 100%[===================>] 408.03M  16.9MB/s    in 25s     \n",
            "\n",
            "2024-11-16 08:00:16 (16.0 MB/s) - ‘DIV2K_train_LR_bicubic_X3.zip’ saved [427847282/427847282]\n",
            "\n",
            "--2024-11-16 08:00:16--  https://data.vision.ee.ethz.ch/cvl/DIV2K/DIV2K_train_LR_bicubic_X4.zip\n",
            "Resolving data.vision.ee.ethz.ch (data.vision.ee.ethz.ch)... 129.132.52.178, 2001:67c:10ec:36c2::178\n",
            "Connecting to data.vision.ee.ethz.ch (data.vision.ee.ethz.ch)|129.132.52.178|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 246914039 (235M) [application/zip]\n",
            "Saving to: ‘DIV2K_train_LR_bicubic_X4.zip’\n",
            "\n",
            "DIV2K_train_LR_bicu 100%[===================>] 235.47M  17.0MB/s    in 15s     \n",
            "\n",
            "2024-11-16 08:00:31 (15.7 MB/s) - ‘DIV2K_train_LR_bicubic_X4.zip’ saved [246914039/246914039]\n",
            "\n",
            "Archive:  DIV2K_train_HR.zip\n",
            "   creating: trainsets/trainH/HR/DIV2K_train_HR/\n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0103.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0413.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0031.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0660.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0126.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0793.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0764.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0550.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0437.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0374.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0755.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0614.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0646.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0371.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0312.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0108.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0556.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0794.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0722.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0780.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0555.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0439.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0396.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0666.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0254.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0344.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0062.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0657.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0117.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0395.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0015.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0335.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0578.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0142.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0719.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0101.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0579.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0504.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0576.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0590.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0158.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0384.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0795.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0668.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0144.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0642.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0427.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0593.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0080.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0050.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0617.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0608.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0118.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0082.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0788.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0042.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0333.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0346.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0705.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0195.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0671.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0213.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0692.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0253.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0191.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0628.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0354.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0003.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0393.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0336.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0674.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0586.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0074.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0116.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0270.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0376.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0650.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0462.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0046.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0545.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0347.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0187.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0713.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0558.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0319.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0073.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0033.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0207.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0290.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0194.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0246.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0034.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0621.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0768.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0366.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0490.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0471.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0475.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0152.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0636.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0338.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0358.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0523.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0456.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0470.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0522.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0426.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0587.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0465.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0236.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0192.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0458.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0438.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0176.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0016.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0392.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0054.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0063.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0537.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0271.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0409.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0328.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0582.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0532.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0706.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0153.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0401.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0110.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0316.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0069.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0209.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0351.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0433.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0534.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0525.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0353.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0018.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0592.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0041.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0398.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0355.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0492.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0258.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0051.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0339.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0156.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0174.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0526.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0168.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0515.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0289.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0700.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0711.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0317.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0310.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0075.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0533.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0345.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0238.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0493.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0019.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0559.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0268.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0746.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0648.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0112.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0639.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0216.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0170.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0408.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0461.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0774.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0308.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0368.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0341.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0535.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0585.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0004.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0496.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0662.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0173.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0200.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0752.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0106.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0520.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0519.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0157.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0552.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0735.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0362.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0410.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0286.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0627.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0557.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0266.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0252.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0206.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0330.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0088.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0728.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0641.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0350.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0083.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0682.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0549.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0564.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0476.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0760.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0629.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0630.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0032.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0581.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0056.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0040.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0169.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0400.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0172.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0182.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0269.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0612.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0649.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0311.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0723.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0166.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0155.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0072.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0149.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0425.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0715.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0670.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0460.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0748.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0147.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0602.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0610.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0479.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0603.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0043.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0190.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0503.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0055.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0337.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0453.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0219.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0548.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0661.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0718.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0489.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0775.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0323.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0664.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0002.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0127.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0322.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0640.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0473.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0730.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0008.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0486.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0597.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0064.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0068.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0510.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0594.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0685.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0497.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0637.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0332.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0208.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0241.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0201.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0044.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0141.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0381.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0412.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0035.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0049.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0181.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0340.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0272.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0279.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0307.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0733.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0250.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0739.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0654.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0343.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0422.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0297.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0360.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0099.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0541.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0616.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0352.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0092.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0528.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0483.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0631.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0134.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0625.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0530.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0454.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0624.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0501.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0038.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0365.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0789.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0010.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0543.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0635.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0418.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0159.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0689.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0429.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0276.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0255.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0293.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0327.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0488.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0244.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0721.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0652.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0779.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0687.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0326.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0161.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0498.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0264.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0136.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0006.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0741.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0421.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0229.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0373.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0703.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0516.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0234.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0405.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0763.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0619.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0138.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0513.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0432.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0177.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0017.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0736.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0459.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0505.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0397.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0591.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0196.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0724.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0740.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0223.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0442.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0165.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0302.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0386.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0601.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0370.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0647.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0267.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0380.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0441.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0037.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0678.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0304.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0494.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0028.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0613.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0257.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0100.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0097.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0604.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0023.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0782.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0446.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0378.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0411.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0320.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0390.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0148.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0577.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0684.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0595.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0765.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0203.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0288.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0058.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0790.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0605.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0248.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0467.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0210.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0517.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0707.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0566.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0224.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0114.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0761.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0468.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0716.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0420.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0669.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0375.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0140.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0792.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0240.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0546.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0235.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0077.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0260.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0212.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0584.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0633.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0060.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0164.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0622.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0105.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0005.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0679.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0089.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0466.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0645.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0301.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0499.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0020.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0070.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0404.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0749.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0770.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0772.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0450.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0120.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0653.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0563.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0171.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0784.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0688.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0045.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0066.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0583.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0632.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0512.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0767.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0623.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0406.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0419.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0273.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0198.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0750.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0220.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0482.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0407.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0704.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0547.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0589.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0012.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0150.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0481.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0357.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0677.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0315.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0394.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0160.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0667.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0568.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0435.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0606.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0464.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0364.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0245.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0508.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0356.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0135.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0146.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0574.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0698.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0222.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0261.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0444.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0078.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0123.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0797.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0274.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0225.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0180.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0325.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0372.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0029.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0318.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0452.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0115.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0423.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0615.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0672.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0231.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0731.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0389.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0680.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0329.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0663.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0659.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0292.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0284.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0133.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0727.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0445.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0139.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0298.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0282.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0778.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0565.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0485.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0495.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0215.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0694.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0321.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0094.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0598.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0430.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0021.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0036.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0188.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0334.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0759.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0217.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0562.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0124.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0690.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0385.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0695.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0708.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0745.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0007.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0226.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0256.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0673.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0451.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0143.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0403.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0125.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0132.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0644.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0796.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0076.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0211.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0676.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0121.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0415.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0536.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0620.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0331.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0277.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0611.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0262.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0305.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0521.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0221.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0699.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0743.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0742.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0111.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0480.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0720.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0402.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0561.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0729.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0296.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0379.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0014.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0714.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0754.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0634.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0725.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0309.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0197.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0039.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0696.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0758.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0599.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0228.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0712.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0539.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0781.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0009.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0145.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0527.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0263.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0122.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0506.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0363.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0249.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0104.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0800.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0214.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0658.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0399.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0572.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0204.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0651.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0061.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0026.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0300.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0162.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0478.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0022.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0079.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0285.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0511.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0025.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0428.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0436.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0324.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0447.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0457.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0424.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0675.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0469.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0090.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0179.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0771.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0431.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0726.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0609.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0184.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0747.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0154.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0391.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0573.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0071.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0798.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0693.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0280.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0414.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0119.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0757.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0762.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0734.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0001.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0265.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0643.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0567.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0130.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0580.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0463.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0218.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0769.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0507.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0013.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0233.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0087.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0093.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0709.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0027.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0570.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0342.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0011.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0287.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0524.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0791.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0701.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0783.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0349.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0766.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0232.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0314.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0303.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0697.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0514.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0377.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0085.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0113.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0540.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0383.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0243.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0086.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0091.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0151.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0502.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0294.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0281.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0656.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0500.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0237.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0387.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0178.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0518.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0239.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0131.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0655.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0417.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0776.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0560.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0737.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0048.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0128.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0052.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0137.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0686.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0053.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0665.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0691.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0167.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0313.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0531.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0569.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0553.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0047.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0096.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0756.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0440.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0199.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0283.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0247.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0024.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0193.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0084.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0102.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0551.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0575.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0477.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0098.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0554.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0189.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0717.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0732.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0702.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0183.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0448.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0455.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0367.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0251.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0744.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0785.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0067.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0163.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0751.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0299.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0129.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0291.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0607.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0242.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0107.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0175.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0753.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0278.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0369.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0571.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0202.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0030.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0799.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0474.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0491.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0638.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0600.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0596.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0059.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0186.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0509.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0529.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0787.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0382.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0777.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0109.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0227.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0388.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0618.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0681.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0205.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0472.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0306.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0361.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0738.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0230.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0081.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0095.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0449.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0626.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0065.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0443.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0275.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0542.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0484.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0359.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0773.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0434.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0544.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0416.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0295.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0538.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0259.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0348.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0588.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0710.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0786.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0185.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0057.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0487.png  \n",
            "  inflating: trainsets/trainH/HR/DIV2K_train_HR/0683.png  \n",
            "Archive:  DIV2K_train_LR_bicubic_X2.zip\n",
            "checkdir:  cannot create extraction directory: trainsets/trainH/LR_bicubic/X2\n",
            "           No such file or directory\n",
            "Archive:  DIV2K_train_LR_bicubic_X3.zip\n",
            "checkdir:  cannot create extraction directory: trainsets/trainH/LR_bicubic/X3\n",
            "           No such file or directory\n",
            "Archive:  DIV2K_train_LR_bicubic_X4.zip\n",
            "checkdir:  cannot create extraction directory: trainsets/trainH/LR_bicubic/X4\n",
            "           No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MrKHxuigAxuf",
        "outputId": "85c950f4-841c-4461-b142-5b0e74ba91b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data\t\t\t\t    main_test_fdncnn.py\t\t main_train_usrnet.py\n",
            "DIV2K_train_HR.zip\t\t    main_test_ffdnet.py\t\t main_train_vrt.py\n",
            "DIV2K_train_LR_bicubic_X2.zip\t    main_test_imdn.py\t\t matlab\n",
            "DIV2K_train_LR_bicubic_X3.zip\t    main_test_ircnn_denoiser.py  models\n",
            "DIV2K_train_LR_bicubic_X4.zip\t    main_test_msrresnet.py\t model_zoo\n",
            "docs\t\t\t\t    main_test_rrdb.py\t\t options\n",
            "figs\t\t\t\t    main_test_rvrt.py\t\t README.md\n",
            "kernels\t\t\t\t    main_test_srmd.py\t\t requirement.txt\n",
            "LICENSE\t\t\t\t    main_test_swinir.py\t\t retinaface\n",
            "main_challenge_sr.py\t\t    main_test_usrnet.py\t\t scripts\n",
            "main_download_pretrained_models.py  main_test_vrt.py\t\t testsets\n",
            "main_test_dncnn3_deblocking.py\t    main_train_dncnn.py\t\t trainsets\n",
            "main_test_dncnn.py\t\t    main_train_drunet.py\t utils\n",
            "main_test_dpsr.py\t\t    main_train_gan.py\n",
            "main_test_face_enhancement.py\t    main_train_psnr.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirement.txt"
      ],
      "metadata": {
        "id": "YwESHsuLyDNi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python main_train_psnr.py --opt options/swinir/train_swinir_sr_classical.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Plpz-EmAI2O5",
        "outputId": "5acf67e7-8b0e-47dd-c220-eb88fd144341"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "export CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7\n",
            "number of GPUs is: 8\n",
            "LogHandlers setup!\n",
            "24-11-19 13:20:38.236 :   task: swinir_sr_classical_patch48_x2\n",
            "  model: plain\n",
            "  gpu_ids: [0, 1, 2, 3, 4, 5, 6, 7]\n",
            "  dist: False\n",
            "  scale: 2\n",
            "  n_channels: 3\n",
            "  path:[\n",
            "    root: superresolution\n",
            "    pretrained_netG: None\n",
            "    pretrained_netE: None\n",
            "    task: superresolution/swinir_sr_classical_patch48_x2\n",
            "    log: superresolution/swinir_sr_classical_patch48_x2\n",
            "    options: superresolution/swinir_sr_classical_patch48_x2/options\n",
            "    models: superresolution/swinir_sr_classical_patch48_x2/models\n",
            "    images: superresolution/swinir_sr_classical_patch48_x2/images\n",
            "    pretrained_optimizerG: None\n",
            "  ]\n",
            "  datasets:[\n",
            "    train:[\n",
            "      name: train_dataset\n",
            "      dataset_type: sr\n",
            "      dataroot_H: trainsets/trainH/HR/DIV2K_train_HR\n",
            "      dataroot_L: trainsets/trainH/LR_bicubic/X4/DIV2K_train_LR_bicubic/X2\n",
            "      H_size: 96\n",
            "      dataloader_shuffle: True\n",
            "      dataloader_num_workers: 2\n",
            "      dataloader_batch_size: 4\n",
            "      phase: train\n",
            "      scale: 2\n",
            "      n_channels: 3\n",
            "    ]\n",
            "    test:[\n",
            "      name: test_dataset\n",
            "      dataset_type: sr\n",
            "      dataroot_H: testsets/Set5/HR\n",
            "      dataroot_L: testsets/Set5/LR_bicubic/X2\n",
            "      phase: test\n",
            "      scale: 2\n",
            "      n_channels: 3\n",
            "    ]\n",
            "  ]\n",
            "  netG:[\n",
            "    net_type: swinir\n",
            "    upscale: 2\n",
            "    in_chans: 3\n",
            "    img_size: 48\n",
            "    window_size: 8\n",
            "    img_range: 1.0\n",
            "    depths: [6, 6, 6, 6, 6, 6]\n",
            "    embed_dim: 180\n",
            "    num_heads: [6, 6, 6, 6, 6, 6]\n",
            "    mlp_ratio: 2\n",
            "    upsampler: pixelshuffle\n",
            "    resi_connection: 1conv\n",
            "    init_type: default\n",
            "    scale: 2\n",
            "  ]\n",
            "  train:[\n",
            "    G_lossfn_type: l1\n",
            "    G_lossfn_weight: 1.0\n",
            "    E_decay: 0.999\n",
            "    G_optimizer_type: adam\n",
            "    G_optimizer_lr: 0.0002\n",
            "    G_optimizer_wd: 0\n",
            "    G_optimizer_clipgrad: None\n",
            "    G_optimizer_reuse: True\n",
            "    G_scheduler_type: MultiStepLR\n",
            "    G_scheduler_milestones: [250000, 400000, 450000, 475000, 500000]\n",
            "    G_scheduler_gamma: 0.5\n",
            "    G_regularizer_orthstep: None\n",
            "    G_regularizer_clipstep: None\n",
            "    G_param_strict: True\n",
            "    E_param_strict: True\n",
            "    checkpoint_test: 5000\n",
            "    checkpoint_save: 5000\n",
            "    checkpoint_print: 200\n",
            "    F_feature_layer: 34\n",
            "    F_weights: 1.0\n",
            "    F_lossfn_type: l1\n",
            "    F_use_input_norm: True\n",
            "    F_use_range_norm: False\n",
            "    G_optimizer_betas: [0.9, 0.999]\n",
            "    G_scheduler_restart_weights: 1\n",
            "  ]\n",
            "  opt_path: options/swinir/train_swinir_sr_classical.json\n",
            "  is_train: True\n",
            "  merge_bn: False\n",
            "  merge_bn_startpoint: -1\n",
            "  find_unused_parameters: False\n",
            "  use_static_graph: False\n",
            "  num_gpu: 8\n",
            "  rank: 0\n",
            "  world_size: 1\n",
            "\n",
            "Random seed: 5822\n",
            "Dataset [DatasetSR - train_dataset] is created.\n",
            "24-11-19 13:20:48.220 : Number of train images: 800, iters: 200\n",
            "Dataset [DatasetSR - test_dataset] is created.\n",
            "/usr/local/lib/python3.10/dist-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
            "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
            "Pass this initialization! Initialization was done during network definition!\n",
            "Pass this initialization! Initialization was done during network definition!\n",
            "Training model [ModelPlain] is created.\n",
            "Copying model for E ...\n",
            "24-11-19 13:21:07.847 : \n",
            "Networks name: SwinIR\n",
            "Params number: 26731289\n",
            "Net structure:\n",
            "SwinIR(\n",
            "  (conv_first): Conv2d(3, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (patch_embed): PatchEmbed(\n",
            "    (norm): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
            "  )\n",
            "  (patch_unembed): PatchUnEmbed()\n",
            "  (pos_drop): Dropout(p=0.0, inplace=False)\n",
            "  (layers): ModuleList(\n",
            "    (0): RSTB(\n",
            "      (residual_group): BasicLayer(\n",
            "        dim=180, input_resolution=(48, 48), depth=6\n",
            "        (blocks): ModuleList(\n",
            "          (0): SwinTransformerBlock(\n",
            "            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2\n",
            "            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
            "            (attn): ContentAdaptiveDynamicWindowModule(\n",
            "              (project_to_embed_dim): Linear(in_features=180, out_features=184, bias=True)\n",
            "              (multi_scale_attention): ModuleList(\n",
            "                (0-2): 3 x MultiheadAttention(\n",
            "                  (out_proj): NonDynamicallyQuantizableLinear(in_features=184, out_features=184, bias=True)\n",
            "                )\n",
            "              )\n",
            "              (fuse_fc): Linear(in_features=552, out_features=180, bias=True)\n",
            "            )\n",
            "            (drop_path): Identity()\n",
            "            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
            "            (mlp): FlexibleLocallyEnhancedFFN(\n",
            "              (fc1): Linear(in_features=180, out_features=360, bias=True)\n",
            "              (depthwise_conv): Conv2d(360, 360, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=360)\n",
            "              (fc2): Linear(in_features=360, out_features=180, bias=True)\n",
            "              (activation): GELU(approximate='none')\n",
            "            )\n",
            "          )\n",
            "          (1): SwinTransformerBlock(\n",
            "            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2\n",
            "            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
            "            (attn): ContentAdaptiveDynamicWindowModule(\n",
            "              (project_to_embed_dim): Linear(in_features=180, out_features=184, bias=True)\n",
            "              (multi_scale_attention): ModuleList(\n",
            "                (0-2): 3 x MultiheadAttention(\n",
            "                  (out_proj): NonDynamicallyQuantizableLinear(in_features=184, out_features=184, bias=True)\n",
            "                )\n",
            "              )\n",
            "              (fuse_fc): Linear(in_features=552, out_features=180, bias=True)\n",
            "            )\n",
            "            (drop_path): DropPath(drop_prob=0.003)\n",
            "            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
            "            (mlp): FlexibleLocallyEnhancedFFN(\n",
            "              (fc1): Linear(in_features=180, out_features=360, bias=True)\n",
            "              (depthwise_conv): Conv2d(360, 360, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=360)\n",
            "              (fc2): Linear(in_features=360, out_features=180, bias=True)\n",
            "              (activation): GELU(approximate='none')\n",
            "            )\n",
            "          )\n",
            "          (2): SwinTransformerBlock(\n",
            "            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2\n",
            "            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
            "            (attn): ContentAdaptiveDynamicWindowModule(\n",
            "              (project_to_embed_dim): Linear(in_features=180, out_features=184, bias=True)\n",
            "              (multi_scale_attention): ModuleList(\n",
            "                (0-2): 3 x MultiheadAttention(\n",
            "                  (out_proj): NonDynamicallyQuantizableLinear(in_features=184, out_features=184, bias=True)\n",
            "                )\n",
            "              )\n",
            "              (fuse_fc): Linear(in_features=552, out_features=180, bias=True)\n",
            "            )\n",
            "            (drop_path): DropPath(drop_prob=0.006)\n",
            "            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
            "            (mlp): FlexibleLocallyEnhancedFFN(\n",
            "              (fc1): Linear(in_features=180, out_features=360, bias=True)\n",
            "              (depthwise_conv): Conv2d(360, 360, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=360)\n",
            "              (fc2): Linear(in_features=360, out_features=180, bias=True)\n",
            "              (activation): GELU(approximate='none')\n",
            "            )\n",
            "          )\n",
            "          (3): SwinTransformerBlock(\n",
            "            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2\n",
            "            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
            "            (attn): ContentAdaptiveDynamicWindowModule(\n",
            "              (project_to_embed_dim): Linear(in_features=180, out_features=184, bias=True)\n",
            "              (multi_scale_attention): ModuleList(\n",
            "                (0-2): 3 x MultiheadAttention(\n",
            "                  (out_proj): NonDynamicallyQuantizableLinear(in_features=184, out_features=184, bias=True)\n",
            "                )\n",
            "              )\n",
            "              (fuse_fc): Linear(in_features=552, out_features=180, bias=True)\n",
            "            )\n",
            "            (drop_path): DropPath(drop_prob=0.009)\n",
            "            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
            "            (mlp): FlexibleLocallyEnhancedFFN(\n",
            "              (fc1): Linear(in_features=180, out_features=360, bias=True)\n",
            "              (depthwise_conv): Conv2d(360, 360, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=360)\n",
            "              (fc2): Linear(in_features=360, out_features=180, bias=True)\n",
            "              (activation): GELU(approximate='none')\n",
            "            )\n",
            "          )\n",
            "          (4): SwinTransformerBlock(\n",
            "            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2\n",
            "            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
            "            (attn): ContentAdaptiveDynamicWindowModule(\n",
            "              (project_to_embed_dim): Linear(in_features=180, out_features=184, bias=True)\n",
            "              (multi_scale_attention): ModuleList(\n",
            "                (0-2): 3 x MultiheadAttention(\n",
            "                  (out_proj): NonDynamicallyQuantizableLinear(in_features=184, out_features=184, bias=True)\n",
            "                )\n",
            "              )\n",
            "              (fuse_fc): Linear(in_features=552, out_features=180, bias=True)\n",
            "            )\n",
            "            (drop_path): DropPath(drop_prob=0.011)\n",
            "            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
            "            (mlp): FlexibleLocallyEnhancedFFN(\n",
            "              (fc1): Linear(in_features=180, out_features=360, bias=True)\n",
            "              (depthwise_conv): Conv2d(360, 360, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=360)\n",
            "              (fc2): Linear(in_features=360, out_features=180, bias=True)\n",
            "              (activation): GELU(approximate='none')\n",
            "            )\n",
            "          )\n",
            "          (5): SwinTransformerBlock(\n",
            "            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2\n",
            "            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
            "            (attn): ContentAdaptiveDynamicWindowModule(\n",
            "              (project_to_embed_dim): Linear(in_features=180, out_features=184, bias=True)\n",
            "              (multi_scale_attention): ModuleList(\n",
            "                (0-2): 3 x MultiheadAttention(\n",
            "                  (out_proj): NonDynamicallyQuantizableLinear(in_features=184, out_features=184, bias=True)\n",
            "                )\n",
            "              )\n",
            "              (fuse_fc): Linear(in_features=552, out_features=180, bias=True)\n",
            "            )\n",
            "            (drop_path): DropPath(drop_prob=0.014)\n",
            "            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
            "            (mlp): FlexibleLocallyEnhancedFFN(\n",
            "              (fc1): Linear(in_features=180, out_features=360, bias=True)\n",
            "              (depthwise_conv): Conv2d(360, 360, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=360)\n",
            "              (fc2): Linear(in_features=360, out_features=180, bias=True)\n",
            "              (activation): GELU(approximate='none')\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (attn_module): AdaptiveMixedAttentionModule(\n",
            "        (spatial_attention): Sequential(\n",
            "          (0): Conv2d(180, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
            "          (1): Sigmoid()\n",
            "        )\n",
            "        (channel_attention): Sequential(\n",
            "          (0): AdaptiveAvgPool2d(output_size=1)\n",
            "          (1): Conv2d(180, 22, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (2): ReLU()\n",
            "          (3): Conv2d(22, 180, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (4): Sigmoid()\n",
            "        )\n",
            "      )\n",
            "      (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (patch_embed): PatchEmbed()\n",
            "      (patch_unembed): PatchUnEmbed()\n",
            "    )\n",
            "    (1): RSTB(\n",
            "      (residual_group): BasicLayer(\n",
            "        dim=180, input_resolution=(48, 48), depth=6\n",
            "        (blocks): ModuleList(\n",
            "          (0): SwinTransformerBlock(\n",
            "            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2\n",
            "            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
            "            (attn): ContentAdaptiveDynamicWindowModule(\n",
            "              (project_to_embed_dim): Linear(in_features=180, out_features=184, bias=True)\n",
            "              (multi_scale_attention): ModuleList(\n",
            "                (0-2): 3 x MultiheadAttention(\n",
            "                  (out_proj): NonDynamicallyQuantizableLinear(in_features=184, out_features=184, bias=True)\n",
            "                )\n",
            "              )\n",
            "              (fuse_fc): Linear(in_features=552, out_features=180, bias=True)\n",
            "            )\n",
            "            (drop_path): DropPath(drop_prob=0.017)\n",
            "            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
            "            (mlp): FlexibleLocallyEnhancedFFN(\n",
            "              (fc1): Linear(in_features=180, out_features=360, bias=True)\n",
            "              (depthwise_conv): Conv2d(360, 360, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=360)\n",
            "              (fc2): Linear(in_features=360, out_features=180, bias=True)\n",
            "              (activation): GELU(approximate='none')\n",
            "            )\n",
            "          )\n",
            "          (1): SwinTransformerBlock(\n",
            "            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2\n",
            "            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
            "            (attn): ContentAdaptiveDynamicWindowModule(\n",
            "              (project_to_embed_dim): Linear(in_features=180, out_features=184, bias=True)\n",
            "              (multi_scale_attention): ModuleList(\n",
            "                (0-2): 3 x MultiheadAttention(\n",
            "                  (out_proj): NonDynamicallyQuantizableLinear(in_features=184, out_features=184, bias=True)\n",
            "                )\n",
            "              )\n",
            "              (fuse_fc): Linear(in_features=552, out_features=180, bias=True)\n",
            "            )\n",
            "            (drop_path): DropPath(drop_prob=0.020)\n",
            "            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
            "            (mlp): FlexibleLocallyEnhancedFFN(\n",
            "              (fc1): Linear(in_features=180, out_features=360, bias=True)\n",
            "              (depthwise_conv): Conv2d(360, 360, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=360)\n",
            "              (fc2): Linear(in_features=360, out_features=180, bias=True)\n",
            "              (activation): GELU(approximate='none')\n",
            "            )\n",
            "          )\n",
            "          (2): SwinTransformerBlock(\n",
            "            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2\n",
            "            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
            "            (attn): ContentAdaptiveDynamicWindowModule(\n",
            "              (project_to_embed_dim): Linear(in_features=180, out_features=184, bias=True)\n",
            "              (multi_scale_attention): ModuleList(\n",
            "                (0-2): 3 x MultiheadAttention(\n",
            "                  (out_proj): NonDynamicallyQuantizableLinear(in_features=184, out_features=184, bias=True)\n",
            "                )\n",
            "              )\n",
            "              (fuse_fc): Linear(in_features=552, out_features=180, bias=True)\n",
            "            )\n",
            "            (drop_path): DropPath(drop_prob=0.023)\n",
            "            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
            "            (mlp): FlexibleLocallyEnhancedFFN(\n",
            "              (fc1): Linear(in_features=180, out_features=360, bias=True)\n",
            "              (depthwise_conv): Conv2d(360, 360, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=360)\n",
            "              (fc2): Linear(in_features=360, out_features=180, bias=True)\n",
            "              (activation): GELU(approximate='none')\n",
            "            )\n",
            "          )\n",
            "          (3): SwinTransformerBlock(\n",
            "            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2\n",
            "            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
            "            (attn): ContentAdaptiveDynamicWindowModule(\n",
            "              (project_to_embed_dim): Linear(in_features=180, out_features=184, bias=True)\n",
            "              (multi_scale_attention): ModuleList(\n",
            "                (0-2): 3 x MultiheadAttention(\n",
            "                  (out_proj): NonDynamicallyQuantizableLinear(in_features=184, out_features=184, bias=True)\n",
            "                )\n",
            "              )\n",
            "              (fuse_fc): Linear(in_features=552, out_features=180, bias=True)\n",
            "            )\n",
            "            (drop_path): DropPath(drop_prob=0.026)\n",
            "            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
            "            (mlp): FlexibleLocallyEnhancedFFN(\n",
            "              (fc1): Linear(in_features=180, out_features=360, bias=True)\n",
            "              (depthwise_conv): Conv2d(360, 360, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=360)\n",
            "              (fc2): Linear(in_features=360, out_features=180, bias=True)\n",
            "              (activation): GELU(approximate='none')\n",
            "            )\n",
            "          )\n",
            "          (4): SwinTransformerBlock(\n",
            "            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2\n",
            "            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
            "            (attn): ContentAdaptiveDynamicWindowModule(\n",
            "              (project_to_embed_dim): Linear(in_features=180, out_features=184, bias=True)\n",
            "              (multi_scale_attention): ModuleList(\n",
            "                (0-2): 3 x MultiheadAttention(\n",
            "                  (out_proj): NonDynamicallyQuantizableLinear(in_features=184, out_features=184, bias=True)\n",
            "                )\n",
            "              )\n",
            "              (fuse_fc): Linear(in_features=552, out_features=180, bias=True)\n",
            "            )\n",
            "            (drop_path): DropPath(drop_prob=0.029)\n",
            "            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
            "            (mlp): FlexibleLocallyEnhancedFFN(\n",
            "              (fc1): Linear(in_features=180, out_features=360, bias=True)\n",
            "              (depthwise_conv): Conv2d(360, 360, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=360)\n",
            "              (fc2): Linear(in_features=360, out_features=180, bias=True)\n",
            "              (activation): GELU(approximate='none')\n",
            "            )\n",
            "          )\n",
            "          (5): SwinTransformerBlock(\n",
            "            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2\n",
            "            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
            "            (attn): ContentAdaptiveDynamicWindowModule(\n",
            "              (project_to_embed_dim): Linear(in_features=180, out_features=184, bias=True)\n",
            "              (multi_scale_attention): ModuleList(\n",
            "                (0-2): 3 x MultiheadAttention(\n",
            "                  (out_proj): NonDynamicallyQuantizableLinear(in_features=184, out_features=184, bias=True)\n",
            "                )\n",
            "              )\n",
            "              (fuse_fc): Linear(in_features=552, out_features=180, bias=True)\n",
            "            )\n",
            "            (drop_path): DropPath(drop_prob=0.031)\n",
            "            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
            "            (mlp): FlexibleLocallyEnhancedFFN(\n",
            "              (fc1): Linear(in_features=180, out_features=360, bias=True)\n",
            "              (depthwise_conv): Conv2d(360, 360, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=360)\n",
            "              (fc2): Linear(in_features=360, out_features=180, bias=True)\n",
            "              (activation): GELU(approximate='none')\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (attn_module): AdaptiveMixedAttentionModule(\n",
            "        (spatial_attention): Sequential(\n",
            "          (0): Conv2d(180, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
            "          (1): Sigmoid()\n",
            "        )\n",
            "        (channel_attention): Sequential(\n",
            "          (0): AdaptiveAvgPool2d(output_size=1)\n",
            "          (1): Conv2d(180, 22, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (2): ReLU()\n",
            "          (3): Conv2d(22, 180, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (4): Sigmoid()\n",
            "        )\n",
            "      )\n",
            "      (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (patch_embed): PatchEmbed()\n",
            "      (patch_unembed): PatchUnEmbed()\n",
            "    )\n",
            "    (2): RSTB(\n",
            "      (residual_group): BasicLayer(\n",
            "        dim=180, input_resolution=(48, 48), depth=6\n",
            "        (blocks): ModuleList(\n",
            "          (0): SwinTransformerBlock(\n",
            "            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2\n",
            "            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
            "            (attn): ContentAdaptiveDynamicWindowModule(\n",
            "              (project_to_embed_dim): Linear(in_features=180, out_features=184, bias=True)\n",
            "              (multi_scale_attention): ModuleList(\n",
            "                (0-2): 3 x MultiheadAttention(\n",
            "                  (out_proj): NonDynamicallyQuantizableLinear(in_features=184, out_features=184, bias=True)\n",
            "                )\n",
            "              )\n",
            "              (fuse_fc): Linear(in_features=552, out_features=180, bias=True)\n",
            "            )\n",
            "            (drop_path): DropPath(drop_prob=0.034)\n",
            "            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
            "            (mlp): FlexibleLocallyEnhancedFFN(\n",
            "              (fc1): Linear(in_features=180, out_features=360, bias=True)\n",
            "              (depthwise_conv): Conv2d(360, 360, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=360)\n",
            "              (fc2): Linear(in_features=360, out_features=180, bias=True)\n",
            "              (activation): GELU(approximate='none')\n",
            "            )\n",
            "          )\n",
            "          (1): SwinTransformerBlock(\n",
            "            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2\n",
            "            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
            "            (attn): ContentAdaptiveDynamicWindowModule(\n",
            "              (project_to_embed_dim): Linear(in_features=180, out_features=184, bias=True)\n",
            "              (multi_scale_attention): ModuleList(\n",
            "                (0-2): 3 x MultiheadAttention(\n",
            "                  (out_proj): NonDynamicallyQuantizableLinear(in_features=184, out_features=184, bias=True)\n",
            "                )\n",
            "              )\n",
            "              (fuse_fc): Linear(in_features=552, out_features=180, bias=True)\n",
            "            )\n",
            "            (drop_path): DropPath(drop_prob=0.037)\n",
            "            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
            "            (mlp): FlexibleLocallyEnhancedFFN(\n",
            "              (fc1): Linear(in_features=180, out_features=360, bias=True)\n",
            "              (depthwise_conv): Conv2d(360, 360, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=360)\n",
            "              (fc2): Linear(in_features=360, out_features=180, bias=True)\n",
            "              (activation): GELU(approximate='none')\n",
            "            )\n",
            "          )\n",
            "          (2): SwinTransformerBlock(\n",
            "            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2\n",
            "            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
            "            (attn): ContentAdaptiveDynamicWindowModule(\n",
            "              (project_to_embed_dim): Linear(in_features=180, out_features=184, bias=True)\n",
            "              (multi_scale_attention): ModuleList(\n",
            "                (0-2): 3 x MultiheadAttention(\n",
            "                  (out_proj): NonDynamicallyQuantizableLinear(in_features=184, out_features=184, bias=True)\n",
            "                )\n",
            "              )\n",
            "              (fuse_fc): Linear(in_features=552, out_features=180, bias=True)\n",
            "            )\n",
            "            (drop_path): DropPath(drop_prob=0.040)\n",
            "            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
            "            (mlp): FlexibleLocallyEnhancedFFN(\n",
            "              (fc1): Linear(in_features=180, out_features=360, bias=True)\n",
            "              (depthwise_conv): Conv2d(360, 360, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=360)\n",
            "              (fc2): Linear(in_features=360, out_features=180, bias=True)\n",
            "              (activation): GELU(approximate='none')\n",
            "            )\n",
            "          )\n",
            "          (3): SwinTransformerBlock(\n",
            "            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2\n",
            "            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
            "            (attn): ContentAdaptiveDynamicWindowModule(\n",
            "              (project_to_embed_dim): Linear(in_features=180, out_features=184, bias=True)\n",
            "              (multi_scale_attention): ModuleList(\n",
            "                (0-2): 3 x MultiheadAttention(\n",
            "                  (out_proj): NonDynamicallyQuantizableLinear(in_features=184, out_features=184, bias=True)\n",
            "                )\n",
            "              )\n",
            "              (fuse_fc): Linear(in_features=552, out_features=180, bias=True)\n",
            "            )\n",
            "            (drop_path): DropPath(drop_prob=0.043)\n",
            "            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
            "            (mlp): FlexibleLocallyEnhancedFFN(\n",
            "              (fc1): Linear(in_features=180, out_features=360, bias=True)\n",
            "              (depthwise_conv): Conv2d(360, 360, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=360)\n",
            "              (fc2): Linear(in_features=360, out_features=180, bias=True)\n",
            "              (activation): GELU(approximate='none')\n",
            "            )\n",
            "          )\n",
            "          (4): SwinTransformerBlock(\n",
            "            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2\n",
            "            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
            "            (attn): ContentAdaptiveDynamicWindowModule(\n",
            "              (project_to_embed_dim): Linear(in_features=180, out_features=184, bias=True)\n",
            "              (multi_scale_attention): ModuleList(\n",
            "                (0-2): 3 x MultiheadAttention(\n",
            "                  (out_proj): NonDynamicallyQuantizableLinear(in_features=184, out_features=184, bias=True)\n",
            "                )\n",
            "              )\n",
            "              (fuse_fc): Linear(in_features=552, out_features=180, bias=True)\n",
            "            )\n",
            "            (drop_path): DropPath(drop_prob=0.046)\n",
            "            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
            "            (mlp): FlexibleLocallyEnhancedFFN(\n",
            "              (fc1): Linear(in_features=180, out_features=360, bias=True)\n",
            "              (depthwise_conv): Conv2d(360, 360, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=360)\n",
            "              (fc2): Linear(in_features=360, out_features=180, bias=True)\n",
            "              (activation): GELU(approximate='none')\n",
            "            )\n",
            "          )\n",
            "          (5): SwinTransformerBlock(\n",
            "            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2\n",
            "            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
            "            (attn): ContentAdaptiveDynamicWindowModule(\n",
            "              (project_to_embed_dim): Linear(in_features=180, out_features=184, bias=True)\n",
            "              (multi_scale_attention): ModuleList(\n",
            "                (0-2): 3 x MultiheadAttention(\n",
            "                  (out_proj): NonDynamicallyQuantizableLinear(in_features=184, out_features=184, bias=True)\n",
            "                )\n",
            "              )\n",
            "              (fuse_fc): Linear(in_features=552, out_features=180, bias=True)\n",
            "            )\n",
            "            (drop_path): DropPath(drop_prob=0.049)\n",
            "            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
            "            (mlp): FlexibleLocallyEnhancedFFN(\n",
            "              (fc1): Linear(in_features=180, out_features=360, bias=True)\n",
            "              (depthwise_conv): Conv2d(360, 360, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=360)\n",
            "              (fc2): Linear(in_features=360, out_features=180, bias=True)\n",
            "              (activation): GELU(approximate='none')\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (attn_module): AdaptiveMixedAttentionModule(\n",
            "        (spatial_attention): Sequential(\n",
            "          (0): Conv2d(180, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
            "          (1): Sigmoid()\n",
            "        )\n",
            "        (channel_attention): Sequential(\n",
            "          (0): AdaptiveAvgPool2d(output_size=1)\n",
            "          (1): Conv2d(180, 22, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (2): ReLU()\n",
            "          (3): Conv2d(22, 180, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (4): Sigmoid()\n",
            "        )\n",
            "      )\n",
            "      (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (patch_embed): PatchEmbed()\n",
            "      (patch_unembed): PatchUnEmbed()\n",
            "    )\n",
            "    (3): RSTB(\n",
            "      (residual_group): BasicLayer(\n",
            "        dim=180, input_resolution=(48, 48), depth=6\n",
            "        (blocks): ModuleList(\n",
            "          (0): SwinTransformerBlock(\n",
            "            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2\n",
            "            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
            "            (attn): ContentAdaptiveDynamicWindowModule(\n",
            "              (project_to_embed_dim): Linear(in_features=180, out_features=184, bias=True)\n",
            "              (multi_scale_attention): ModuleList(\n",
            "                (0-2): 3 x MultiheadAttention(\n",
            "                  (out_proj): NonDynamicallyQuantizableLinear(in_features=184, out_features=184, bias=True)\n",
            "                )\n",
            "              )\n",
            "              (fuse_fc): Linear(in_features=552, out_features=180, bias=True)\n",
            "            )\n",
            "            (drop_path): DropPath(drop_prob=0.051)\n",
            "            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
            "            (mlp): FlexibleLocallyEnhancedFFN(\n",
            "              (fc1): Linear(in_features=180, out_features=360, bias=True)\n",
            "              (depthwise_conv): Conv2d(360, 360, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=360)\n",
            "              (fc2): Linear(in_features=360, out_features=180, bias=True)\n",
            "              (activation): GELU(approximate='none')\n",
            "            )\n",
            "          )\n",
            "          (1): SwinTransformerBlock(\n",
            "            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2\n",
            "            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
            "            (attn): ContentAdaptiveDynamicWindowModule(\n",
            "              (project_to_embed_dim): Linear(in_features=180, out_features=184, bias=True)\n",
            "              (multi_scale_attention): ModuleList(\n",
            "                (0-2): 3 x MultiheadAttention(\n",
            "                  (out_proj): NonDynamicallyQuantizableLinear(in_features=184, out_features=184, bias=True)\n",
            "                )\n",
            "              )\n",
            "              (fuse_fc): Linear(in_features=552, out_features=180, bias=True)\n",
            "            )\n",
            "            (drop_path): DropPath(drop_prob=0.054)\n",
            "            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
            "            (mlp): FlexibleLocallyEnhancedFFN(\n",
            "              (fc1): Linear(in_features=180, out_features=360, bias=True)\n",
            "              (depthwise_conv): Conv2d(360, 360, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=360)\n",
            "              (fc2): Linear(in_features=360, out_features=180, bias=True)\n",
            "              (activation): GELU(approximate='none')\n",
            "            )\n",
            "          )\n",
            "          (2): SwinTransformerBlock(\n",
            "            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2\n",
            "            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
            "            (attn): ContentAdaptiveDynamicWindowModule(\n",
            "              (project_to_embed_dim): Linear(in_features=180, out_features=184, bias=True)\n",
            "              (multi_scale_attention): ModuleList(\n",
            "                (0-2): 3 x MultiheadAttention(\n",
            "                  (out_proj): NonDynamicallyQuantizableLinear(in_features=184, out_features=184, bias=True)\n",
            "                )\n",
            "              )\n",
            "              (fuse_fc): Linear(in_features=552, out_features=180, bias=True)\n",
            "            )\n",
            "            (drop_path): DropPath(drop_prob=0.057)\n",
            "            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
            "            (mlp): FlexibleLocallyEnhancedFFN(\n",
            "              (fc1): Linear(in_features=180, out_features=360, bias=True)\n",
            "              (depthwise_conv): Conv2d(360, 360, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=360)\n",
            "              (fc2): Linear(in_features=360, out_features=180, bias=True)\n",
            "              (activation): GELU(approximate='none')\n",
            "            )\n",
            "          )\n",
            "          (3): SwinTransformerBlock(\n",
            "            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2\n",
            "            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
            "            (attn): ContentAdaptiveDynamicWindowModule(\n",
            "              (project_to_embed_dim): Linear(in_features=180, out_features=184, bias=True)\n",
            "              (multi_scale_attention): ModuleList(\n",
            "                (0-2): 3 x MultiheadAttention(\n",
            "                  (out_proj): NonDynamicallyQuantizableLinear(in_features=184, out_features=184, bias=True)\n",
            "                )\n",
            "              )\n",
            "              (fuse_fc): Linear(in_features=552, out_features=180, bias=True)\n",
            "            )\n",
            "            (drop_path): DropPath(drop_prob=0.060)\n",
            "            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
            "            (mlp): FlexibleLocallyEnhancedFFN(\n",
            "              (fc1): Linear(in_features=180, out_features=360, bias=True)\n",
            "              (depthwise_conv): Conv2d(360, 360, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=360)\n",
            "              (fc2): Linear(in_features=360, out_features=180, bias=True)\n",
            "              (activation): GELU(approximate='none')\n",
            "            )\n",
            "          )\n",
            "          (4): SwinTransformerBlock(\n",
            "            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2\n",
            "            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
            "            (attn): ContentAdaptiveDynamicWindowModule(\n",
            "              (project_to_embed_dim): Linear(in_features=180, out_features=184, bias=True)\n",
            "              (multi_scale_attention): ModuleList(\n",
            "                (0-2): 3 x MultiheadAttention(\n",
            "                  (out_proj): NonDynamicallyQuantizableLinear(in_features=184, out_features=184, bias=True)\n",
            "                )\n",
            "              )\n",
            "              (fuse_fc): Linear(in_features=552, out_features=180, bias=True)\n",
            "            )\n",
            "            (drop_path): DropPath(drop_prob=0.063)\n",
            "            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
            "            (mlp): FlexibleLocallyEnhancedFFN(\n",
            "              (fc1): Linear(in_features=180, out_features=360, bias=True)\n",
            "              (depthwise_conv): Conv2d(360, 360, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=360)\n",
            "              (fc2): Linear(in_features=360, out_features=180, bias=True)\n",
            "              (activation): GELU(approximate='none')\n",
            "            )\n",
            "          )\n",
            "          (5): SwinTransformerBlock(\n",
            "            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2\n",
            "            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
            "            (attn): ContentAdaptiveDynamicWindowModule(\n",
            "              (project_to_embed_dim): Linear(in_features=180, out_features=184, bias=True)\n",
            "              (multi_scale_attention): ModuleList(\n",
            "                (0-2): 3 x MultiheadAttention(\n",
            "                  (out_proj): NonDynamicallyQuantizableLinear(in_features=184, out_features=184, bias=True)\n",
            "                )\n",
            "              )\n",
            "              (fuse_fc): Linear(in_features=552, out_features=180, bias=True)\n",
            "            )\n",
            "            (drop_path): DropPath(drop_prob=0.066)\n",
            "            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
            "            (mlp): FlexibleLocallyEnhancedFFN(\n",
            "              (fc1): Linear(in_features=180, out_features=360, bias=True)\n",
            "              (depthwise_conv): Conv2d(360, 360, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=360)\n",
            "              (fc2): Linear(in_features=360, out_features=180, bias=True)\n",
            "              (activation): GELU(approximate='none')\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (attn_module): AdaptiveMixedAttentionModule(\n",
            "        (spatial_attention): Sequential(\n",
            "          (0): Conv2d(180, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
            "          (1): Sigmoid()\n",
            "        )\n",
            "        (channel_attention): Sequential(\n",
            "          (0): AdaptiveAvgPool2d(output_size=1)\n",
            "          (1): Conv2d(180, 22, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (2): ReLU()\n",
            "          (3): Conv2d(22, 180, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (4): Sigmoid()\n",
            "        )\n",
            "      )\n",
            "      (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (patch_embed): PatchEmbed()\n",
            "      (patch_unembed): PatchUnEmbed()\n",
            "    )\n",
            "    (4): RSTB(\n",
            "      (residual_group): BasicLayer(\n",
            "        dim=180, input_resolution=(48, 48), depth=6\n",
            "        (blocks): ModuleList(\n",
            "          (0): SwinTransformerBlock(\n",
            "            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2\n",
            "            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
            "            (attn): ContentAdaptiveDynamicWindowModule(\n",
            "              (project_to_embed_dim): Linear(in_features=180, out_features=184, bias=True)\n",
            "              (multi_scale_attention): ModuleList(\n",
            "                (0-2): 3 x MultiheadAttention(\n",
            "                  (out_proj): NonDynamicallyQuantizableLinear(in_features=184, out_features=184, bias=True)\n",
            "                )\n",
            "              )\n",
            "              (fuse_fc): Linear(in_features=552, out_features=180, bias=True)\n",
            "            )\n",
            "            (drop_path): DropPath(drop_prob=0.069)\n",
            "            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
            "            (mlp): FlexibleLocallyEnhancedFFN(\n",
            "              (fc1): Linear(in_features=180, out_features=360, bias=True)\n",
            "              (depthwise_conv): Conv2d(360, 360, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=360)\n",
            "              (fc2): Linear(in_features=360, out_features=180, bias=True)\n",
            "              (activation): GELU(approximate='none')\n",
            "            )\n",
            "          )\n",
            "          (1): SwinTransformerBlock(\n",
            "            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2\n",
            "            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
            "            (attn): ContentAdaptiveDynamicWindowModule(\n",
            "              (project_to_embed_dim): Linear(in_features=180, out_features=184, bias=True)\n",
            "              (multi_scale_attention): ModuleList(\n",
            "                (0-2): 3 x MultiheadAttention(\n",
            "                  (out_proj): NonDynamicallyQuantizableLinear(in_features=184, out_features=184, bias=True)\n",
            "                )\n",
            "              )\n",
            "              (fuse_fc): Linear(in_features=552, out_features=180, bias=True)\n",
            "            )\n",
            "            (drop_path): DropPath(drop_prob=0.071)\n",
            "            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
            "            (mlp): FlexibleLocallyEnhancedFFN(\n",
            "              (fc1): Linear(in_features=180, out_features=360, bias=True)\n",
            "              (depthwise_conv): Conv2d(360, 360, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=360)\n",
            "              (fc2): Linear(in_features=360, out_features=180, bias=True)\n",
            "              (activation): GELU(approximate='none')\n",
            "            )\n",
            "          )\n",
            "          (2): SwinTransformerBlock(\n",
            "            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2\n",
            "            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
            "            (attn): ContentAdaptiveDynamicWindowModule(\n",
            "              (project_to_embed_dim): Linear(in_features=180, out_features=184, bias=True)\n",
            "              (multi_scale_attention): ModuleList(\n",
            "                (0-2): 3 x MultiheadAttention(\n",
            "                  (out_proj): NonDynamicallyQuantizableLinear(in_features=184, out_features=184, bias=True)\n",
            "                )\n",
            "              )\n",
            "              (fuse_fc): Linear(in_features=552, out_features=180, bias=True)\n",
            "            )\n",
            "            (drop_path): DropPath(drop_prob=0.074)\n",
            "            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
            "            (mlp): FlexibleLocallyEnhancedFFN(\n",
            "              (fc1): Linear(in_features=180, out_features=360, bias=True)\n",
            "              (depthwise_conv): Conv2d(360, 360, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=360)\n",
            "              (fc2): Linear(in_features=360, out_features=180, bias=True)\n",
            "              (activation): GELU(approximate='none')\n",
            "            )\n",
            "          )\n",
            "          (3): SwinTransformerBlock(\n",
            "            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2\n",
            "            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
            "            (attn): ContentAdaptiveDynamicWindowModule(\n",
            "              (project_to_embed_dim): Linear(in_features=180, out_features=184, bias=True)\n",
            "              (multi_scale_attention): ModuleList(\n",
            "                (0-2): 3 x MultiheadAttention(\n",
            "                  (out_proj): NonDynamicallyQuantizableLinear(in_features=184, out_features=184, bias=True)\n",
            "                )\n",
            "              )\n",
            "              (fuse_fc): Linear(in_features=552, out_features=180, bias=True)\n",
            "            )\n",
            "            (drop_path): DropPath(drop_prob=0.077)\n",
            "            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
            "            (mlp): FlexibleLocallyEnhancedFFN(\n",
            "              (fc1): Linear(in_features=180, out_features=360, bias=True)\n",
            "              (depthwise_conv): Conv2d(360, 360, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=360)\n",
            "              (fc2): Linear(in_features=360, out_features=180, bias=True)\n",
            "              (activation): GELU(approximate='none')\n",
            "            )\n",
            "          )\n",
            "          (4): SwinTransformerBlock(\n",
            "            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2\n",
            "            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
            "            (attn): ContentAdaptiveDynamicWindowModule(\n",
            "              (project_to_embed_dim): Linear(in_features=180, out_features=184, bias=True)\n",
            "              (multi_scale_attention): ModuleList(\n",
            "                (0-2): 3 x MultiheadAttention(\n",
            "                  (out_proj): NonDynamicallyQuantizableLinear(in_features=184, out_features=184, bias=True)\n",
            "                )\n",
            "              )\n",
            "              (fuse_fc): Linear(in_features=552, out_features=180, bias=True)\n",
            "            )\n",
            "            (drop_path): DropPath(drop_prob=0.080)\n",
            "            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
            "            (mlp): FlexibleLocallyEnhancedFFN(\n",
            "              (fc1): Linear(in_features=180, out_features=360, bias=True)\n",
            "              (depthwise_conv): Conv2d(360, 360, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=360)\n",
            "              (fc2): Linear(in_features=360, out_features=180, bias=True)\n",
            "              (activation): GELU(approximate='none')\n",
            "            )\n",
            "          )\n",
            "          (5): SwinTransformerBlock(\n",
            "            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2\n",
            "            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
            "            (attn): ContentAdaptiveDynamicWindowModule(\n",
            "              (project_to_embed_dim): Linear(in_features=180, out_features=184, bias=True)\n",
            "              (multi_scale_attention): ModuleList(\n",
            "                (0-2): 3 x MultiheadAttention(\n",
            "                  (out_proj): NonDynamicallyQuantizableLinear(in_features=184, out_features=184, bias=True)\n",
            "                )\n",
            "              )\n",
            "              (fuse_fc): Linear(in_features=552, out_features=180, bias=True)\n",
            "            )\n",
            "            (drop_path): DropPath(drop_prob=0.083)\n",
            "            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
            "            (mlp): FlexibleLocallyEnhancedFFN(\n",
            "              (fc1): Linear(in_features=180, out_features=360, bias=True)\n",
            "              (depthwise_conv): Conv2d(360, 360, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=360)\n",
            "              (fc2): Linear(in_features=360, out_features=180, bias=True)\n",
            "              (activation): GELU(approximate='none')\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (attn_module): AdaptiveMixedAttentionModule(\n",
            "        (spatial_attention): Sequential(\n",
            "          (0): Conv2d(180, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
            "          (1): Sigmoid()\n",
            "        )\n",
            "        (channel_attention): Sequential(\n",
            "          (0): AdaptiveAvgPool2d(output_size=1)\n",
            "          (1): Conv2d(180, 22, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (2): ReLU()\n",
            "          (3): Conv2d(22, 180, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (4): Sigmoid()\n",
            "        )\n",
            "      )\n",
            "      (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (patch_embed): PatchEmbed()\n",
            "      (patch_unembed): PatchUnEmbed()\n",
            "    )\n",
            "    (5): RSTB(\n",
            "      (residual_group): BasicLayer(\n",
            "        dim=180, input_resolution=(48, 48), depth=6\n",
            "        (blocks): ModuleList(\n",
            "          (0): SwinTransformerBlock(\n",
            "            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2\n",
            "            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
            "            (attn): ContentAdaptiveDynamicWindowModule(\n",
            "              (project_to_embed_dim): Linear(in_features=180, out_features=184, bias=True)\n",
            "              (multi_scale_attention): ModuleList(\n",
            "                (0-2): 3 x MultiheadAttention(\n",
            "                  (out_proj): NonDynamicallyQuantizableLinear(in_features=184, out_features=184, bias=True)\n",
            "                )\n",
            "              )\n",
            "              (fuse_fc): Linear(in_features=552, out_features=180, bias=True)\n",
            "            )\n",
            "            (drop_path): DropPath(drop_prob=0.086)\n",
            "            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
            "            (mlp): FlexibleLocallyEnhancedFFN(\n",
            "              (fc1): Linear(in_features=180, out_features=360, bias=True)\n",
            "              (depthwise_conv): Conv2d(360, 360, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=360)\n",
            "              (fc2): Linear(in_features=360, out_features=180, bias=True)\n",
            "              (activation): GELU(approximate='none')\n",
            "            )\n",
            "          )\n",
            "          (1): SwinTransformerBlock(\n",
            "            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2\n",
            "            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
            "            (attn): ContentAdaptiveDynamicWindowModule(\n",
            "              (project_to_embed_dim): Linear(in_features=180, out_features=184, bias=True)\n",
            "              (multi_scale_attention): ModuleList(\n",
            "                (0-2): 3 x MultiheadAttention(\n",
            "                  (out_proj): NonDynamicallyQuantizableLinear(in_features=184, out_features=184, bias=True)\n",
            "                )\n",
            "              )\n",
            "              (fuse_fc): Linear(in_features=552, out_features=180, bias=True)\n",
            "            )\n",
            "            (drop_path): DropPath(drop_prob=0.089)\n",
            "            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
            "            (mlp): FlexibleLocallyEnhancedFFN(\n",
            "              (fc1): Linear(in_features=180, out_features=360, bias=True)\n",
            "              (depthwise_conv): Conv2d(360, 360, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=360)\n",
            "              (fc2): Linear(in_features=360, out_features=180, bias=True)\n",
            "              (activation): GELU(approximate='none')\n",
            "            )\n",
            "          )\n",
            "          (2): SwinTransformerBlock(\n",
            "            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2\n",
            "            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
            "            (attn): ContentAdaptiveDynamicWindowModule(\n",
            "              (project_to_embed_dim): Linear(in_features=180, out_features=184, bias=True)\n",
            "              (multi_scale_attention): ModuleList(\n",
            "                (0-2): 3 x MultiheadAttention(\n",
            "                  (out_proj): NonDynamicallyQuantizableLinear(in_features=184, out_features=184, bias=True)\n",
            "                )\n",
            "              )\n",
            "              (fuse_fc): Linear(in_features=552, out_features=180, bias=True)\n",
            "            )\n",
            "            (drop_path): DropPath(drop_prob=0.091)\n",
            "            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
            "            (mlp): FlexibleLocallyEnhancedFFN(\n",
            "              (fc1): Linear(in_features=180, out_features=360, bias=True)\n",
            "              (depthwise_conv): Conv2d(360, 360, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=360)\n",
            "              (fc2): Linear(in_features=360, out_features=180, bias=True)\n",
            "              (activation): GELU(approximate='none')\n",
            "            )\n",
            "          )\n",
            "          (3): SwinTransformerBlock(\n",
            "            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2\n",
            "            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
            "            (attn): ContentAdaptiveDynamicWindowModule(\n",
            "              (project_to_embed_dim): Linear(in_features=180, out_features=184, bias=True)\n",
            "              (multi_scale_attention): ModuleList(\n",
            "                (0-2): 3 x MultiheadAttention(\n",
            "                  (out_proj): NonDynamicallyQuantizableLinear(in_features=184, out_features=184, bias=True)\n",
            "                )\n",
            "              )\n",
            "              (fuse_fc): Linear(in_features=552, out_features=180, bias=True)\n",
            "            )\n",
            "            (drop_path): DropPath(drop_prob=0.094)\n",
            "            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
            "            (mlp): FlexibleLocallyEnhancedFFN(\n",
            "              (fc1): Linear(in_features=180, out_features=360, bias=True)\n",
            "              (depthwise_conv): Conv2d(360, 360, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=360)\n",
            "              (fc2): Linear(in_features=360, out_features=180, bias=True)\n",
            "              (activation): GELU(approximate='none')\n",
            "            )\n",
            "          )\n",
            "          (4): SwinTransformerBlock(\n",
            "            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2\n",
            "            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
            "            (attn): ContentAdaptiveDynamicWindowModule(\n",
            "              (project_to_embed_dim): Linear(in_features=180, out_features=184, bias=True)\n",
            "              (multi_scale_attention): ModuleList(\n",
            "                (0-2): 3 x MultiheadAttention(\n",
            "                  (out_proj): NonDynamicallyQuantizableLinear(in_features=184, out_features=184, bias=True)\n",
            "                )\n",
            "              )\n",
            "              (fuse_fc): Linear(in_features=552, out_features=180, bias=True)\n",
            "            )\n",
            "            (drop_path): DropPath(drop_prob=0.097)\n",
            "            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
            "            (mlp): FlexibleLocallyEnhancedFFN(\n",
            "              (fc1): Linear(in_features=180, out_features=360, bias=True)\n",
            "              (depthwise_conv): Conv2d(360, 360, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=360)\n",
            "              (fc2): Linear(in_features=360, out_features=180, bias=True)\n",
            "              (activation): GELU(approximate='none')\n",
            "            )\n",
            "          )\n",
            "          (5): SwinTransformerBlock(\n",
            "            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2\n",
            "            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
            "            (attn): ContentAdaptiveDynamicWindowModule(\n",
            "              (project_to_embed_dim): Linear(in_features=180, out_features=184, bias=True)\n",
            "              (multi_scale_attention): ModuleList(\n",
            "                (0-2): 3 x MultiheadAttention(\n",
            "                  (out_proj): NonDynamicallyQuantizableLinear(in_features=184, out_features=184, bias=True)\n",
            "                )\n",
            "              )\n",
            "              (fuse_fc): Linear(in_features=552, out_features=180, bias=True)\n",
            "            )\n",
            "            (drop_path): DropPath(drop_prob=0.100)\n",
            "            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
            "            (mlp): FlexibleLocallyEnhancedFFN(\n",
            "              (fc1): Linear(in_features=180, out_features=360, bias=True)\n",
            "              (depthwise_conv): Conv2d(360, 360, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=360)\n",
            "              (fc2): Linear(in_features=360, out_features=180, bias=True)\n",
            "              (activation): GELU(approximate='none')\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (attn_module): AdaptiveMixedAttentionModule(\n",
            "        (spatial_attention): Sequential(\n",
            "          (0): Conv2d(180, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
            "          (1): Sigmoid()\n",
            "        )\n",
            "        (channel_attention): Sequential(\n",
            "          (0): AdaptiveAvgPool2d(output_size=1)\n",
            "          (1): Conv2d(180, 22, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (2): ReLU()\n",
            "          (3): Conv2d(22, 180, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (4): Sigmoid()\n",
            "        )\n",
            "      )\n",
            "      (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (patch_embed): PatchEmbed()\n",
            "      (patch_unembed): PatchUnEmbed()\n",
            "    )\n",
            "  )\n",
            "  (norm): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
            "  (conv_after_body): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv_before_upsample): Sequential(\n",
            "    (0): Conv2d(180, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "  )\n",
            "  (upsample): Upsample(\n",
            "    (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): PixelShuffle(upscale_factor=2)\n",
            "  )\n",
            "  (conv_last): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            ")\n",
            "\n",
            "/content/drive/MyDrive/KAIR/models/model_base.py:136: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at ../aten/src/ATen/native/ReduceOps.cpp:1823.)\n",
            "  msg += ' | {:>6.3f} | {:>6.3f} | {:>6.3f} | {:>6.3f} | {} || {:s}'.format(v.mean(), v.min(), v.max(), v.std(), v.shape, name) + '\\n'\n",
            "24-11-19 13:21:08.807 : \n",
            " |  mean  |  min   |  max   |  std   || shape               \n",
            " | -0.002 | -0.192 |  0.192 |  0.111 | torch.Size([180, 3, 3, 3]) || conv_first.weight\n",
            " | -0.009 | -0.192 |  0.189 |  0.109 | torch.Size([180]) || conv_first.bias\n",
            " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || patch_embed.norm.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || patch_embed.norm.bias\n",
            " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.0.norm1.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.0.norm1.bias\n",
            " |  0.000 | -0.079 |  0.088 |  0.020 | torch.Size([184, 180]) || layers.0.residual_group.blocks.0.attn.project_to_embed_dim.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.0.residual_group.blocks.0.attn.project_to_embed_dim.bias\n",
            " | -0.000 | -0.090 |  0.090 |  0.052 | torch.Size([552, 184]) || layers.0.residual_group.blocks.0.attn.multi_scale_attention.0.in_proj_weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([552]) || layers.0.residual_group.blocks.0.attn.multi_scale_attention.0.in_proj_bias\n",
            " |  0.000 | -0.093 |  0.082 |  0.020 | torch.Size([184, 184]) || layers.0.residual_group.blocks.0.attn.multi_scale_attention.0.out_proj.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.0.residual_group.blocks.0.attn.multi_scale_attention.0.out_proj.bias\n",
            " | -0.000 | -0.090 |  0.090 |  0.052 | torch.Size([552, 184]) || layers.0.residual_group.blocks.0.attn.multi_scale_attention.1.in_proj_weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([552]) || layers.0.residual_group.blocks.0.attn.multi_scale_attention.1.in_proj_bias\n",
            " |  0.000 | -0.084 |  0.080 |  0.020 | torch.Size([184, 184]) || layers.0.residual_group.blocks.0.attn.multi_scale_attention.1.out_proj.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.0.residual_group.blocks.0.attn.multi_scale_attention.1.out_proj.bias\n",
            " | -0.000 | -0.090 |  0.090 |  0.052 | torch.Size([552, 184]) || layers.0.residual_group.blocks.0.attn.multi_scale_attention.2.in_proj_weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([552]) || layers.0.residual_group.blocks.0.attn.multi_scale_attention.2.in_proj_bias\n",
            " | -0.000 | -0.082 |  0.082 |  0.020 | torch.Size([184, 184]) || layers.0.residual_group.blocks.0.attn.multi_scale_attention.2.out_proj.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.0.residual_group.blocks.0.attn.multi_scale_attention.2.out_proj.bias\n",
            " |  0.000 | -0.080 |  0.082 |  0.020 | torch.Size([180, 552]) || layers.0.residual_group.blocks.0.attn.fuse_fc.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.0.attn.fuse_fc.bias\n",
            " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.0.norm2.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.0.norm2.bias\n",
            " | -0.000 | -0.081 |  0.080 |  0.020 | torch.Size([360, 180]) || layers.0.residual_group.blocks.0.mlp.fc1.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.0.residual_group.blocks.0.mlp.fc1.bias\n",
            " | -0.001 | -0.333 |  0.333 |  0.195 | torch.Size([360, 1, 3, 3]) || layers.0.residual_group.blocks.0.mlp.depthwise_conv.weight\n",
            " |  0.006 | -0.330 |  0.330 |  0.191 | torch.Size([360]) || layers.0.residual_group.blocks.0.mlp.depthwise_conv.bias\n",
            " | -0.000 | -0.084 |  0.077 |  0.020 | torch.Size([180, 360]) || layers.0.residual_group.blocks.0.mlp.fc2.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.0.mlp.fc2.bias\n",
            " | -15.972 | -100.000 |  0.000 | 36.635 | torch.Size([36, 64, 64]) || layers.0.residual_group.blocks.1.attn_mask\n",
            " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.1.norm1.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.1.norm1.bias\n",
            " |  0.000 | -0.086 |  0.079 |  0.020 | torch.Size([184, 180]) || layers.0.residual_group.blocks.1.attn.project_to_embed_dim.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.0.residual_group.blocks.1.attn.project_to_embed_dim.bias\n",
            " | -0.000 | -0.090 |  0.090 |  0.052 | torch.Size([552, 184]) || layers.0.residual_group.blocks.1.attn.multi_scale_attention.0.in_proj_weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([552]) || layers.0.residual_group.blocks.1.attn.multi_scale_attention.0.in_proj_bias\n",
            " |  0.000 | -0.082 |  0.089 |  0.020 | torch.Size([184, 184]) || layers.0.residual_group.blocks.1.attn.multi_scale_attention.0.out_proj.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.0.residual_group.blocks.1.attn.multi_scale_attention.0.out_proj.bias\n",
            " |  0.000 | -0.090 |  0.090 |  0.052 | torch.Size([552, 184]) || layers.0.residual_group.blocks.1.attn.multi_scale_attention.1.in_proj_weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([552]) || layers.0.residual_group.blocks.1.attn.multi_scale_attention.1.in_proj_bias\n",
            " |  0.000 | -0.081 |  0.090 |  0.020 | torch.Size([184, 184]) || layers.0.residual_group.blocks.1.attn.multi_scale_attention.1.out_proj.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.0.residual_group.blocks.1.attn.multi_scale_attention.1.out_proj.bias\n",
            " | -0.000 | -0.090 |  0.090 |  0.052 | torch.Size([552, 184]) || layers.0.residual_group.blocks.1.attn.multi_scale_attention.2.in_proj_weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([552]) || layers.0.residual_group.blocks.1.attn.multi_scale_attention.2.in_proj_bias\n",
            " |  0.000 | -0.086 |  0.074 |  0.020 | torch.Size([184, 184]) || layers.0.residual_group.blocks.1.attn.multi_scale_attention.2.out_proj.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.0.residual_group.blocks.1.attn.multi_scale_attention.2.out_proj.bias\n",
            " |  0.000 | -0.096 |  0.092 |  0.020 | torch.Size([180, 552]) || layers.0.residual_group.blocks.1.attn.fuse_fc.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.1.attn.fuse_fc.bias\n",
            " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.1.norm2.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.1.norm2.bias\n",
            " | -0.000 | -0.080 |  0.084 |  0.020 | torch.Size([360, 180]) || layers.0.residual_group.blocks.1.mlp.fc1.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.0.residual_group.blocks.1.mlp.fc1.bias\n",
            " |  0.003 | -0.333 |  0.333 |  0.193 | torch.Size([360, 1, 3, 3]) || layers.0.residual_group.blocks.1.mlp.depthwise_conv.weight\n",
            " |  0.009 | -0.332 |  0.332 |  0.189 | torch.Size([360]) || layers.0.residual_group.blocks.1.mlp.depthwise_conv.bias\n",
            " | -0.000 | -0.085 |  0.087 |  0.020 | torch.Size([180, 360]) || layers.0.residual_group.blocks.1.mlp.fc2.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.1.mlp.fc2.bias\n",
            " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.2.norm1.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.2.norm1.bias\n",
            " |  0.000 | -0.078 |  0.088 |  0.020 | torch.Size([184, 180]) || layers.0.residual_group.blocks.2.attn.project_to_embed_dim.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.0.residual_group.blocks.2.attn.project_to_embed_dim.bias\n",
            " | -0.000 | -0.090 |  0.090 |  0.052 | torch.Size([552, 184]) || layers.0.residual_group.blocks.2.attn.multi_scale_attention.0.in_proj_weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([552]) || layers.0.residual_group.blocks.2.attn.multi_scale_attention.0.in_proj_bias\n",
            " | -0.000 | -0.087 |  0.075 |  0.020 | torch.Size([184, 184]) || layers.0.residual_group.blocks.2.attn.multi_scale_attention.0.out_proj.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.0.residual_group.blocks.2.attn.multi_scale_attention.0.out_proj.bias\n",
            " |  0.000 | -0.090 |  0.090 |  0.052 | torch.Size([552, 184]) || layers.0.residual_group.blocks.2.attn.multi_scale_attention.1.in_proj_weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([552]) || layers.0.residual_group.blocks.2.attn.multi_scale_attention.1.in_proj_bias\n",
            " | -0.000 | -0.081 |  0.075 |  0.020 | torch.Size([184, 184]) || layers.0.residual_group.blocks.2.attn.multi_scale_attention.1.out_proj.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.0.residual_group.blocks.2.attn.multi_scale_attention.1.out_proj.bias\n",
            " |  0.000 | -0.090 |  0.090 |  0.052 | torch.Size([552, 184]) || layers.0.residual_group.blocks.2.attn.multi_scale_attention.2.in_proj_weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([552]) || layers.0.residual_group.blocks.2.attn.multi_scale_attention.2.in_proj_bias\n",
            " |  0.000 | -0.083 |  0.084 |  0.020 | torch.Size([184, 184]) || layers.0.residual_group.blocks.2.attn.multi_scale_attention.2.out_proj.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.0.residual_group.blocks.2.attn.multi_scale_attention.2.out_proj.bias\n",
            " |  0.000 | -0.084 |  0.095 |  0.020 | torch.Size([180, 552]) || layers.0.residual_group.blocks.2.attn.fuse_fc.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.2.attn.fuse_fc.bias\n",
            " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.2.norm2.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.2.norm2.bias\n",
            " |  0.000 | -0.098 |  0.087 |  0.020 | torch.Size([360, 180]) || layers.0.residual_group.blocks.2.mlp.fc1.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.0.residual_group.blocks.2.mlp.fc1.bias\n",
            " | -0.002 | -0.333 |  0.333 |  0.192 | torch.Size([360, 1, 3, 3]) || layers.0.residual_group.blocks.2.mlp.depthwise_conv.weight\n",
            " |  0.008 | -0.330 |  0.333 |  0.195 | torch.Size([360]) || layers.0.residual_group.blocks.2.mlp.depthwise_conv.bias\n",
            " | -0.000 | -0.082 |  0.085 |  0.020 | torch.Size([180, 360]) || layers.0.residual_group.blocks.2.mlp.fc2.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.2.mlp.fc2.bias\n",
            " | -15.972 | -100.000 |  0.000 | 36.635 | torch.Size([36, 64, 64]) || layers.0.residual_group.blocks.3.attn_mask\n",
            " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.3.norm1.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.3.norm1.bias\n",
            " |  0.000 | -0.087 |  0.082 |  0.020 | torch.Size([184, 180]) || layers.0.residual_group.blocks.3.attn.project_to_embed_dim.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.0.residual_group.blocks.3.attn.project_to_embed_dim.bias\n",
            " | -0.000 | -0.090 |  0.090 |  0.052 | torch.Size([552, 184]) || layers.0.residual_group.blocks.3.attn.multi_scale_attention.0.in_proj_weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([552]) || layers.0.residual_group.blocks.3.attn.multi_scale_attention.0.in_proj_bias\n",
            " |  0.000 | -0.085 |  0.094 |  0.020 | torch.Size([184, 184]) || layers.0.residual_group.blocks.3.attn.multi_scale_attention.0.out_proj.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.0.residual_group.blocks.3.attn.multi_scale_attention.0.out_proj.bias\n",
            " | -0.000 | -0.090 |  0.090 |  0.052 | torch.Size([552, 184]) || layers.0.residual_group.blocks.3.attn.multi_scale_attention.1.in_proj_weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([552]) || layers.0.residual_group.blocks.3.attn.multi_scale_attention.1.in_proj_bias\n",
            " |  0.000 | -0.084 |  0.079 |  0.020 | torch.Size([184, 184]) || layers.0.residual_group.blocks.3.attn.multi_scale_attention.1.out_proj.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.0.residual_group.blocks.3.attn.multi_scale_attention.1.out_proj.bias\n",
            " |  0.000 | -0.090 |  0.090 |  0.052 | torch.Size([552, 184]) || layers.0.residual_group.blocks.3.attn.multi_scale_attention.2.in_proj_weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([552]) || layers.0.residual_group.blocks.3.attn.multi_scale_attention.2.in_proj_bias\n",
            " | -0.000 | -0.082 |  0.089 |  0.020 | torch.Size([184, 184]) || layers.0.residual_group.blocks.3.attn.multi_scale_attention.2.out_proj.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.0.residual_group.blocks.3.attn.multi_scale_attention.2.out_proj.bias\n",
            " |  0.000 | -0.089 |  0.098 |  0.020 | torch.Size([180, 552]) || layers.0.residual_group.blocks.3.attn.fuse_fc.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.3.attn.fuse_fc.bias\n",
            " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.3.norm2.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.3.norm2.bias\n",
            " |  0.000 | -0.077 |  0.089 |  0.020 | torch.Size([360, 180]) || layers.0.residual_group.blocks.3.mlp.fc1.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.0.residual_group.blocks.3.mlp.fc1.bias\n",
            " |  0.003 | -0.333 |  0.333 |  0.192 | torch.Size([360, 1, 3, 3]) || layers.0.residual_group.blocks.3.mlp.depthwise_conv.weight\n",
            " | -0.004 | -0.333 |  0.332 |  0.196 | torch.Size([360]) || layers.0.residual_group.blocks.3.mlp.depthwise_conv.bias\n",
            " |  0.000 | -0.085 |  0.087 |  0.020 | torch.Size([180, 360]) || layers.0.residual_group.blocks.3.mlp.fc2.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.3.mlp.fc2.bias\n",
            " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.4.norm1.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.4.norm1.bias\n",
            " |  0.000 | -0.075 |  0.078 |  0.020 | torch.Size([184, 180]) || layers.0.residual_group.blocks.4.attn.project_to_embed_dim.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.0.residual_group.blocks.4.attn.project_to_embed_dim.bias\n",
            " | -0.000 | -0.090 |  0.090 |  0.052 | torch.Size([552, 184]) || layers.0.residual_group.blocks.4.attn.multi_scale_attention.0.in_proj_weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([552]) || layers.0.residual_group.blocks.4.attn.multi_scale_attention.0.in_proj_bias\n",
            " |  0.000 | -0.077 |  0.082 |  0.020 | torch.Size([184, 184]) || layers.0.residual_group.blocks.4.attn.multi_scale_attention.0.out_proj.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.0.residual_group.blocks.4.attn.multi_scale_attention.0.out_proj.bias\n",
            " |  0.000 | -0.090 |  0.090 |  0.052 | torch.Size([552, 184]) || layers.0.residual_group.blocks.4.attn.multi_scale_attention.1.in_proj_weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([552]) || layers.0.residual_group.blocks.4.attn.multi_scale_attention.1.in_proj_bias\n",
            " | -0.000 | -0.080 |  0.079 |  0.020 | torch.Size([184, 184]) || layers.0.residual_group.blocks.4.attn.multi_scale_attention.1.out_proj.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.0.residual_group.blocks.4.attn.multi_scale_attention.1.out_proj.bias\n",
            " |  0.000 | -0.090 |  0.090 |  0.052 | torch.Size([552, 184]) || layers.0.residual_group.blocks.4.attn.multi_scale_attention.2.in_proj_weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([552]) || layers.0.residual_group.blocks.4.attn.multi_scale_attention.2.in_proj_bias\n",
            " | -0.000 | -0.086 |  0.089 |  0.020 | torch.Size([184, 184]) || layers.0.residual_group.blocks.4.attn.multi_scale_attention.2.out_proj.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.0.residual_group.blocks.4.attn.multi_scale_attention.2.out_proj.bias\n",
            " | -0.000 | -0.098 |  0.076 |  0.020 | torch.Size([180, 552]) || layers.0.residual_group.blocks.4.attn.fuse_fc.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.4.attn.fuse_fc.bias\n",
            " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.4.norm2.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.4.norm2.bias\n",
            " |  0.000 | -0.088 |  0.084 |  0.020 | torch.Size([360, 180]) || layers.0.residual_group.blocks.4.mlp.fc1.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.0.residual_group.blocks.4.mlp.fc1.bias\n",
            " | -0.007 | -0.333 |  0.333 |  0.189 | torch.Size([360, 1, 3, 3]) || layers.0.residual_group.blocks.4.mlp.depthwise_conv.weight\n",
            " | -0.015 | -0.333 |  0.331 |  0.196 | torch.Size([360]) || layers.0.residual_group.blocks.4.mlp.depthwise_conv.bias\n",
            " | -0.000 | -0.081 |  0.083 |  0.020 | torch.Size([180, 360]) || layers.0.residual_group.blocks.4.mlp.fc2.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.4.mlp.fc2.bias\n",
            " | -15.972 | -100.000 |  0.000 | 36.635 | torch.Size([36, 64, 64]) || layers.0.residual_group.blocks.5.attn_mask\n",
            " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.5.norm1.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.5.norm1.bias\n",
            " | -0.000 | -0.088 |  0.092 |  0.020 | torch.Size([184, 180]) || layers.0.residual_group.blocks.5.attn.project_to_embed_dim.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.0.residual_group.blocks.5.attn.project_to_embed_dim.bias\n",
            " | -0.000 | -0.090 |  0.090 |  0.052 | torch.Size([552, 184]) || layers.0.residual_group.blocks.5.attn.multi_scale_attention.0.in_proj_weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([552]) || layers.0.residual_group.blocks.5.attn.multi_scale_attention.0.in_proj_bias\n",
            " | -0.000 | -0.098 |  0.087 |  0.020 | torch.Size([184, 184]) || layers.0.residual_group.blocks.5.attn.multi_scale_attention.0.out_proj.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.0.residual_group.blocks.5.attn.multi_scale_attention.0.out_proj.bias\n",
            " |  0.000 | -0.090 |  0.090 |  0.052 | torch.Size([552, 184]) || layers.0.residual_group.blocks.5.attn.multi_scale_attention.1.in_proj_weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([552]) || layers.0.residual_group.blocks.5.attn.multi_scale_attention.1.in_proj_bias\n",
            " |  0.000 | -0.091 |  0.083 |  0.020 | torch.Size([184, 184]) || layers.0.residual_group.blocks.5.attn.multi_scale_attention.1.out_proj.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.0.residual_group.blocks.5.attn.multi_scale_attention.1.out_proj.bias\n",
            " |  0.000 | -0.090 |  0.090 |  0.052 | torch.Size([552, 184]) || layers.0.residual_group.blocks.5.attn.multi_scale_attention.2.in_proj_weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([552]) || layers.0.residual_group.blocks.5.attn.multi_scale_attention.2.in_proj_bias\n",
            " |  0.000 | -0.082 |  0.098 |  0.020 | torch.Size([184, 184]) || layers.0.residual_group.blocks.5.attn.multi_scale_attention.2.out_proj.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.0.residual_group.blocks.5.attn.multi_scale_attention.2.out_proj.bias\n",
            " |  0.000 | -0.086 |  0.088 |  0.020 | torch.Size([180, 552]) || layers.0.residual_group.blocks.5.attn.fuse_fc.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.5.attn.fuse_fc.bias\n",
            " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.5.norm2.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.5.norm2.bias\n",
            " | -0.000 | -0.092 |  0.089 |  0.020 | torch.Size([360, 180]) || layers.0.residual_group.blocks.5.mlp.fc1.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.0.residual_group.blocks.5.mlp.fc1.bias\n",
            " | -0.004 | -0.333 |  0.333 |  0.195 | torch.Size([360, 1, 3, 3]) || layers.0.residual_group.blocks.5.mlp.depthwise_conv.weight\n",
            " |  0.003 | -0.333 |  0.332 |  0.190 | torch.Size([360]) || layers.0.residual_group.blocks.5.mlp.depthwise_conv.bias\n",
            " |  0.000 | -0.099 |  0.081 |  0.020 | torch.Size([180, 360]) || layers.0.residual_group.blocks.5.mlp.fc2.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.5.mlp.fc2.bias\n",
            " |  0.000 | -0.011 |  0.011 |  0.006 | torch.Size([1, 180, 7, 7]) || layers.0.attn_module.spatial_attention.0.weight\n",
            " |  0.010 |  0.010 |  0.010 |    nan | torch.Size([1]) || layers.0.attn_module.spatial_attention.0.bias\n",
            " | -0.000 | -0.074 |  0.075 |  0.044 | torch.Size([22, 180, 1, 1]) || layers.0.attn_module.channel_attention.1.weight\n",
            " | -0.025 | -0.072 |  0.072 |  0.046 | torch.Size([22]) || layers.0.attn_module.channel_attention.1.bias\n",
            " | -0.003 | -0.213 |  0.213 |  0.124 | torch.Size([180, 22, 1, 1]) || layers.0.attn_module.channel_attention.3.weight\n",
            " |  0.022 | -0.212 |  0.208 |  0.122 | torch.Size([180]) || layers.0.attn_module.channel_attention.3.bias\n",
            " | -0.000 | -0.025 |  0.025 |  0.014 | torch.Size([180, 180, 3, 3]) || layers.0.conv.weight\n",
            " |  0.000 | -0.024 |  0.024 |  0.014 | torch.Size([180]) || layers.0.conv.bias\n",
            " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.0.norm1.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.0.norm1.bias\n",
            " | -0.000 | -0.072 |  0.077 |  0.020 | torch.Size([184, 180]) || layers.1.residual_group.blocks.0.attn.project_to_embed_dim.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.1.residual_group.blocks.0.attn.project_to_embed_dim.bias\n",
            " |  0.000 | -0.090 |  0.090 |  0.052 | torch.Size([552, 184]) || layers.1.residual_group.blocks.0.attn.multi_scale_attention.0.in_proj_weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([552]) || layers.1.residual_group.blocks.0.attn.multi_scale_attention.0.in_proj_bias\n",
            " |  0.000 | -0.080 |  0.082 |  0.020 | torch.Size([184, 184]) || layers.1.residual_group.blocks.0.attn.multi_scale_attention.0.out_proj.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.1.residual_group.blocks.0.attn.multi_scale_attention.0.out_proj.bias\n",
            " | -0.000 | -0.090 |  0.090 |  0.052 | torch.Size([552, 184]) || layers.1.residual_group.blocks.0.attn.multi_scale_attention.1.in_proj_weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([552]) || layers.1.residual_group.blocks.0.attn.multi_scale_attention.1.in_proj_bias\n",
            " | -0.000 | -0.086 |  0.091 |  0.020 | torch.Size([184, 184]) || layers.1.residual_group.blocks.0.attn.multi_scale_attention.1.out_proj.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.1.residual_group.blocks.0.attn.multi_scale_attention.1.out_proj.bias\n",
            " |  0.000 | -0.090 |  0.090 |  0.052 | torch.Size([552, 184]) || layers.1.residual_group.blocks.0.attn.multi_scale_attention.2.in_proj_weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([552]) || layers.1.residual_group.blocks.0.attn.multi_scale_attention.2.in_proj_bias\n",
            " | -0.000 | -0.073 |  0.082 |  0.020 | torch.Size([184, 184]) || layers.1.residual_group.blocks.0.attn.multi_scale_attention.2.out_proj.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.1.residual_group.blocks.0.attn.multi_scale_attention.2.out_proj.bias\n",
            " |  0.000 | -0.095 |  0.084 |  0.020 | torch.Size([180, 552]) || layers.1.residual_group.blocks.0.attn.fuse_fc.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.0.attn.fuse_fc.bias\n",
            " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.0.norm2.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.0.norm2.bias\n",
            " |  0.000 | -0.081 |  0.083 |  0.020 | torch.Size([360, 180]) || layers.1.residual_group.blocks.0.mlp.fc1.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.1.residual_group.blocks.0.mlp.fc1.bias\n",
            " |  0.001 | -0.333 |  0.333 |  0.191 | torch.Size([360, 1, 3, 3]) || layers.1.residual_group.blocks.0.mlp.depthwise_conv.weight\n",
            " | -0.001 | -0.331 |  0.329 |  0.179 | torch.Size([360]) || layers.1.residual_group.blocks.0.mlp.depthwise_conv.bias\n",
            " | -0.000 | -0.077 |  0.088 |  0.020 | torch.Size([180, 360]) || layers.1.residual_group.blocks.0.mlp.fc2.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.0.mlp.fc2.bias\n",
            " | -15.972 | -100.000 |  0.000 | 36.635 | torch.Size([36, 64, 64]) || layers.1.residual_group.blocks.1.attn_mask\n",
            " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.1.norm1.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.1.norm1.bias\n",
            " |  0.000 | -0.084 |  0.080 |  0.020 | torch.Size([184, 180]) || layers.1.residual_group.blocks.1.attn.project_to_embed_dim.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.1.residual_group.blocks.1.attn.project_to_embed_dim.bias\n",
            " | -0.000 | -0.090 |  0.090 |  0.052 | torch.Size([552, 184]) || layers.1.residual_group.blocks.1.attn.multi_scale_attention.0.in_proj_weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([552]) || layers.1.residual_group.blocks.1.attn.multi_scale_attention.0.in_proj_bias\n",
            " |  0.000 | -0.081 |  0.092 |  0.020 | torch.Size([184, 184]) || layers.1.residual_group.blocks.1.attn.multi_scale_attention.0.out_proj.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.1.residual_group.blocks.1.attn.multi_scale_attention.0.out_proj.bias\n",
            " |  0.000 | -0.090 |  0.090 |  0.052 | torch.Size([552, 184]) || layers.1.residual_group.blocks.1.attn.multi_scale_attention.1.in_proj_weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([552]) || layers.1.residual_group.blocks.1.attn.multi_scale_attention.1.in_proj_bias\n",
            " | -0.000 | -0.095 |  0.092 |  0.020 | torch.Size([184, 184]) || layers.1.residual_group.blocks.1.attn.multi_scale_attention.1.out_proj.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.1.residual_group.blocks.1.attn.multi_scale_attention.1.out_proj.bias\n",
            " |  0.000 | -0.090 |  0.090 |  0.052 | torch.Size([552, 184]) || layers.1.residual_group.blocks.1.attn.multi_scale_attention.2.in_proj_weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([552]) || layers.1.residual_group.blocks.1.attn.multi_scale_attention.2.in_proj_bias\n",
            " |  0.000 | -0.084 |  0.079 |  0.020 | torch.Size([184, 184]) || layers.1.residual_group.blocks.1.attn.multi_scale_attention.2.out_proj.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.1.residual_group.blocks.1.attn.multi_scale_attention.2.out_proj.bias\n",
            " |  0.000 | -0.094 |  0.087 |  0.020 | torch.Size([180, 552]) || layers.1.residual_group.blocks.1.attn.fuse_fc.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.1.attn.fuse_fc.bias\n",
            " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.1.norm2.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.1.norm2.bias\n",
            " | -0.000 | -0.085 |  0.095 |  0.020 | torch.Size([360, 180]) || layers.1.residual_group.blocks.1.mlp.fc1.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.1.residual_group.blocks.1.mlp.fc1.bias\n",
            " | -0.004 | -0.333 |  0.333 |  0.193 | torch.Size([360, 1, 3, 3]) || layers.1.residual_group.blocks.1.mlp.depthwise_conv.weight\n",
            " |  0.015 | -0.333 |  0.333 |  0.199 | torch.Size([360]) || layers.1.residual_group.blocks.1.mlp.depthwise_conv.bias\n",
            " | -0.000 | -0.084 |  0.086 |  0.020 | torch.Size([180, 360]) || layers.1.residual_group.blocks.1.mlp.fc2.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.1.mlp.fc2.bias\n",
            " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.2.norm1.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.2.norm1.bias\n",
            " | -0.000 | -0.076 |  0.084 |  0.020 | torch.Size([184, 180]) || layers.1.residual_group.blocks.2.attn.project_to_embed_dim.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.1.residual_group.blocks.2.attn.project_to_embed_dim.bias\n",
            " | -0.000 | -0.090 |  0.090 |  0.052 | torch.Size([552, 184]) || layers.1.residual_group.blocks.2.attn.multi_scale_attention.0.in_proj_weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([552]) || layers.1.residual_group.blocks.2.attn.multi_scale_attention.0.in_proj_bias\n",
            " |  0.000 | -0.082 |  0.086 |  0.020 | torch.Size([184, 184]) || layers.1.residual_group.blocks.2.attn.multi_scale_attention.0.out_proj.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.1.residual_group.blocks.2.attn.multi_scale_attention.0.out_proj.bias\n",
            " |  0.000 | -0.090 |  0.090 |  0.052 | torch.Size([552, 184]) || layers.1.residual_group.blocks.2.attn.multi_scale_attention.1.in_proj_weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([552]) || layers.1.residual_group.blocks.2.attn.multi_scale_attention.1.in_proj_bias\n",
            " | -0.000 | -0.083 |  0.086 |  0.020 | torch.Size([184, 184]) || layers.1.residual_group.blocks.2.attn.multi_scale_attention.1.out_proj.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.1.residual_group.blocks.2.attn.multi_scale_attention.1.out_proj.bias\n",
            " | -0.000 | -0.090 |  0.090 |  0.052 | torch.Size([552, 184]) || layers.1.residual_group.blocks.2.attn.multi_scale_attention.2.in_proj_weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([552]) || layers.1.residual_group.blocks.2.attn.multi_scale_attention.2.in_proj_bias\n",
            " | -0.000 | -0.080 |  0.078 |  0.020 | torch.Size([184, 184]) || layers.1.residual_group.blocks.2.attn.multi_scale_attention.2.out_proj.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.1.residual_group.blocks.2.attn.multi_scale_attention.2.out_proj.bias\n",
            " |  0.000 | -0.098 |  0.086 |  0.020 | torch.Size([180, 552]) || layers.1.residual_group.blocks.2.attn.fuse_fc.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.2.attn.fuse_fc.bias\n",
            " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.2.norm2.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.2.norm2.bias\n",
            " |  0.000 | -0.081 |  0.088 |  0.020 | torch.Size([360, 180]) || layers.1.residual_group.blocks.2.mlp.fc1.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.1.residual_group.blocks.2.mlp.fc1.bias\n",
            " |  0.002 | -0.333 |  0.333 |  0.192 | torch.Size([360, 1, 3, 3]) || layers.1.residual_group.blocks.2.mlp.depthwise_conv.weight\n",
            " | -0.002 | -0.332 |  0.333 |  0.195 | torch.Size([360]) || layers.1.residual_group.blocks.2.mlp.depthwise_conv.bias\n",
            " |  0.000 | -0.081 |  0.073 |  0.020 | torch.Size([180, 360]) || layers.1.residual_group.blocks.2.mlp.fc2.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.2.mlp.fc2.bias\n",
            " | -15.972 | -100.000 |  0.000 | 36.635 | torch.Size([36, 64, 64]) || layers.1.residual_group.blocks.3.attn_mask\n",
            " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.3.norm1.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.3.norm1.bias\n",
            " |  0.000 | -0.090 |  0.078 |  0.020 | torch.Size([184, 180]) || layers.1.residual_group.blocks.3.attn.project_to_embed_dim.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.1.residual_group.blocks.3.attn.project_to_embed_dim.bias\n",
            " | -0.000 | -0.090 |  0.090 |  0.052 | torch.Size([552, 184]) || layers.1.residual_group.blocks.3.attn.multi_scale_attention.0.in_proj_weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([552]) || layers.1.residual_group.blocks.3.attn.multi_scale_attention.0.in_proj_bias\n",
            " | -0.000 | -0.073 |  0.083 |  0.020 | torch.Size([184, 184]) || layers.1.residual_group.blocks.3.attn.multi_scale_attention.0.out_proj.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.1.residual_group.blocks.3.attn.multi_scale_attention.0.out_proj.bias\n",
            " |  0.000 | -0.090 |  0.090 |  0.052 | torch.Size([552, 184]) || layers.1.residual_group.blocks.3.attn.multi_scale_attention.1.in_proj_weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([552]) || layers.1.residual_group.blocks.3.attn.multi_scale_attention.1.in_proj_bias\n",
            " |  0.000 | -0.091 |  0.088 |  0.020 | torch.Size([184, 184]) || layers.1.residual_group.blocks.3.attn.multi_scale_attention.1.out_proj.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.1.residual_group.blocks.3.attn.multi_scale_attention.1.out_proj.bias\n",
            " | -0.000 | -0.090 |  0.090 |  0.052 | torch.Size([552, 184]) || layers.1.residual_group.blocks.3.attn.multi_scale_attention.2.in_proj_weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([552]) || layers.1.residual_group.blocks.3.attn.multi_scale_attention.2.in_proj_bias\n",
            " |  0.000 | -0.078 |  0.078 |  0.020 | torch.Size([184, 184]) || layers.1.residual_group.blocks.3.attn.multi_scale_attention.2.out_proj.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.1.residual_group.blocks.3.attn.multi_scale_attention.2.out_proj.bias\n",
            " | -0.000 | -0.087 |  0.094 |  0.020 | torch.Size([180, 552]) || layers.1.residual_group.blocks.3.attn.fuse_fc.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.3.attn.fuse_fc.bias\n",
            " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.3.norm2.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.3.norm2.bias\n",
            " |  0.000 | -0.091 |  0.080 |  0.020 | torch.Size([360, 180]) || layers.1.residual_group.blocks.3.mlp.fc1.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.1.residual_group.blocks.3.mlp.fc1.bias\n",
            " |  0.006 | -0.333 |  0.333 |  0.194 | torch.Size([360, 1, 3, 3]) || layers.1.residual_group.blocks.3.mlp.depthwise_conv.weight\n",
            " |  0.004 | -0.333 |  0.331 |  0.199 | torch.Size([360]) || layers.1.residual_group.blocks.3.mlp.depthwise_conv.bias\n",
            " | -0.000 | -0.085 |  0.080 |  0.020 | torch.Size([180, 360]) || layers.1.residual_group.blocks.3.mlp.fc2.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.3.mlp.fc2.bias\n",
            " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.4.norm1.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.4.norm1.bias\n",
            " |  0.000 | -0.084 |  0.087 |  0.020 | torch.Size([184, 180]) || layers.1.residual_group.blocks.4.attn.project_to_embed_dim.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.1.residual_group.blocks.4.attn.project_to_embed_dim.bias\n",
            " |  0.000 | -0.090 |  0.090 |  0.052 | torch.Size([552, 184]) || layers.1.residual_group.blocks.4.attn.multi_scale_attention.0.in_proj_weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([552]) || layers.1.residual_group.blocks.4.attn.multi_scale_attention.0.in_proj_bias\n",
            " | -0.000 | -0.082 |  0.080 |  0.020 | torch.Size([184, 184]) || layers.1.residual_group.blocks.4.attn.multi_scale_attention.0.out_proj.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.1.residual_group.blocks.4.attn.multi_scale_attention.0.out_proj.bias\n",
            " |  0.000 | -0.090 |  0.090 |  0.052 | torch.Size([552, 184]) || layers.1.residual_group.blocks.4.attn.multi_scale_attention.1.in_proj_weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([552]) || layers.1.residual_group.blocks.4.attn.multi_scale_attention.1.in_proj_bias\n",
            " | -0.000 | -0.079 |  0.077 |  0.020 | torch.Size([184, 184]) || layers.1.residual_group.blocks.4.attn.multi_scale_attention.1.out_proj.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.1.residual_group.blocks.4.attn.multi_scale_attention.1.out_proj.bias\n",
            " | -0.000 | -0.090 |  0.090 |  0.052 | torch.Size([552, 184]) || layers.1.residual_group.blocks.4.attn.multi_scale_attention.2.in_proj_weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([552]) || layers.1.residual_group.blocks.4.attn.multi_scale_attention.2.in_proj_bias\n",
            " | -0.000 | -0.081 |  0.081 |  0.020 | torch.Size([184, 184]) || layers.1.residual_group.blocks.4.attn.multi_scale_attention.2.out_proj.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.1.residual_group.blocks.4.attn.multi_scale_attention.2.out_proj.bias\n",
            " | -0.000 | -0.097 |  0.082 |  0.020 | torch.Size([180, 552]) || layers.1.residual_group.blocks.4.attn.fuse_fc.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.4.attn.fuse_fc.bias\n",
            " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.4.norm2.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.4.norm2.bias\n",
            " |  0.000 | -0.082 |  0.082 |  0.020 | torch.Size([360, 180]) || layers.1.residual_group.blocks.4.mlp.fc1.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.1.residual_group.blocks.4.mlp.fc1.bias\n",
            " | -0.001 | -0.333 |  0.333 |  0.195 | torch.Size([360, 1, 3, 3]) || layers.1.residual_group.blocks.4.mlp.depthwise_conv.weight\n",
            " |  0.002 | -0.333 |  0.332 |  0.201 | torch.Size([360]) || layers.1.residual_group.blocks.4.mlp.depthwise_conv.bias\n",
            " |  0.000 | -0.087 |  0.082 |  0.020 | torch.Size([180, 360]) || layers.1.residual_group.blocks.4.mlp.fc2.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.4.mlp.fc2.bias\n",
            " | -15.972 | -100.000 |  0.000 | 36.635 | torch.Size([36, 64, 64]) || layers.1.residual_group.blocks.5.attn_mask\n",
            " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.5.norm1.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.5.norm1.bias\n",
            " |  0.000 | -0.085 |  0.079 |  0.020 | torch.Size([184, 180]) || layers.1.residual_group.blocks.5.attn.project_to_embed_dim.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.1.residual_group.blocks.5.attn.project_to_embed_dim.bias\n",
            " |  0.000 | -0.090 |  0.090 |  0.052 | torch.Size([552, 184]) || layers.1.residual_group.blocks.5.attn.multi_scale_attention.0.in_proj_weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([552]) || layers.1.residual_group.blocks.5.attn.multi_scale_attention.0.in_proj_bias\n",
            " |  0.000 | -0.078 |  0.081 |  0.020 | torch.Size([184, 184]) || layers.1.residual_group.blocks.5.attn.multi_scale_attention.0.out_proj.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.1.residual_group.blocks.5.attn.multi_scale_attention.0.out_proj.bias\n",
            " |  0.000 | -0.090 |  0.090 |  0.052 | torch.Size([552, 184]) || layers.1.residual_group.blocks.5.attn.multi_scale_attention.1.in_proj_weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([552]) || layers.1.residual_group.blocks.5.attn.multi_scale_attention.1.in_proj_bias\n",
            " | -0.000 | -0.079 |  0.078 |  0.020 | torch.Size([184, 184]) || layers.1.residual_group.blocks.5.attn.multi_scale_attention.1.out_proj.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.1.residual_group.blocks.5.attn.multi_scale_attention.1.out_proj.bias\n",
            " | -0.000 | -0.090 |  0.090 |  0.052 | torch.Size([552, 184]) || layers.1.residual_group.blocks.5.attn.multi_scale_attention.2.in_proj_weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([552]) || layers.1.residual_group.blocks.5.attn.multi_scale_attention.2.in_proj_bias\n",
            " |  0.000 | -0.087 |  0.088 |  0.020 | torch.Size([184, 184]) || layers.1.residual_group.blocks.5.attn.multi_scale_attention.2.out_proj.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.1.residual_group.blocks.5.attn.multi_scale_attention.2.out_proj.bias\n",
            " | -0.000 | -0.092 |  0.089 |  0.020 | torch.Size([180, 552]) || layers.1.residual_group.blocks.5.attn.fuse_fc.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.5.attn.fuse_fc.bias\n",
            " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.5.norm2.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.5.norm2.bias\n",
            " | -0.000 | -0.095 |  0.081 |  0.020 | torch.Size([360, 180]) || layers.1.residual_group.blocks.5.mlp.fc1.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.1.residual_group.blocks.5.mlp.fc1.bias\n",
            " |  0.002 | -0.333 |  0.333 |  0.192 | torch.Size([360, 1, 3, 3]) || layers.1.residual_group.blocks.5.mlp.depthwise_conv.weight\n",
            " |  0.007 | -0.330 |  0.332 |  0.190 | torch.Size([360]) || layers.1.residual_group.blocks.5.mlp.depthwise_conv.bias\n",
            " | -0.000 | -0.088 |  0.102 |  0.020 | torch.Size([180, 360]) || layers.1.residual_group.blocks.5.mlp.fc2.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.5.mlp.fc2.bias\n",
            " |  0.000 | -0.011 |  0.011 |  0.006 | torch.Size([1, 180, 7, 7]) || layers.1.attn_module.spatial_attention.0.weight\n",
            " |  0.007 |  0.007 |  0.007 |    nan | torch.Size([1]) || layers.1.attn_module.spatial_attention.0.bias\n",
            " | -0.000 | -0.075 |  0.075 |  0.043 | torch.Size([22, 180, 1, 1]) || layers.1.attn_module.channel_attention.1.weight\n",
            " |  0.005 | -0.074 |  0.067 |  0.047 | torch.Size([22]) || layers.1.attn_module.channel_attention.1.bias\n",
            " |  0.004 | -0.213 |  0.213 |  0.123 | torch.Size([180, 22, 1, 1]) || layers.1.attn_module.channel_attention.3.weight\n",
            " |  0.013 | -0.208 |  0.211 |  0.123 | torch.Size([180]) || layers.1.attn_module.channel_attention.3.bias\n",
            " | -0.000 | -0.025 |  0.025 |  0.014 | torch.Size([180, 180, 3, 3]) || layers.1.conv.weight\n",
            " |  0.000 | -0.024 |  0.024 |  0.015 | torch.Size([180]) || layers.1.conv.bias\n",
            " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.0.norm1.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.0.norm1.bias\n",
            " | -0.000 | -0.081 |  0.082 |  0.020 | torch.Size([184, 180]) || layers.2.residual_group.blocks.0.attn.project_to_embed_dim.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.2.residual_group.blocks.0.attn.project_to_embed_dim.bias\n",
            " |  0.000 | -0.090 |  0.090 |  0.052 | torch.Size([552, 184]) || layers.2.residual_group.blocks.0.attn.multi_scale_attention.0.in_proj_weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([552]) || layers.2.residual_group.blocks.0.attn.multi_scale_attention.0.in_proj_bias\n",
            " | -0.000 | -0.083 |  0.075 |  0.020 | torch.Size([184, 184]) || layers.2.residual_group.blocks.0.attn.multi_scale_attention.0.out_proj.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.2.residual_group.blocks.0.attn.multi_scale_attention.0.out_proj.bias\n",
            " | -0.000 | -0.090 |  0.090 |  0.052 | torch.Size([552, 184]) || layers.2.residual_group.blocks.0.attn.multi_scale_attention.1.in_proj_weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([552]) || layers.2.residual_group.blocks.0.attn.multi_scale_attention.1.in_proj_bias\n",
            " |  0.000 | -0.078 |  0.080 |  0.020 | torch.Size([184, 184]) || layers.2.residual_group.blocks.0.attn.multi_scale_attention.1.out_proj.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.2.residual_group.blocks.0.attn.multi_scale_attention.1.out_proj.bias\n",
            " |  0.000 | -0.090 |  0.090 |  0.052 | torch.Size([552, 184]) || layers.2.residual_group.blocks.0.attn.multi_scale_attention.2.in_proj_weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([552]) || layers.2.residual_group.blocks.0.attn.multi_scale_attention.2.in_proj_bias\n",
            " |  0.000 | -0.084 |  0.089 |  0.020 | torch.Size([184, 184]) || layers.2.residual_group.blocks.0.attn.multi_scale_attention.2.out_proj.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.2.residual_group.blocks.0.attn.multi_scale_attention.2.out_proj.bias\n",
            " |  0.000 | -0.088 |  0.084 |  0.020 | torch.Size([180, 552]) || layers.2.residual_group.blocks.0.attn.fuse_fc.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.0.attn.fuse_fc.bias\n",
            " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.0.norm2.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.0.norm2.bias\n",
            " |  0.000 | -0.089 |  0.081 |  0.020 | torch.Size([360, 180]) || layers.2.residual_group.blocks.0.mlp.fc1.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.2.residual_group.blocks.0.mlp.fc1.bias\n",
            " | -0.000 | -0.333 |  0.333 |  0.194 | torch.Size([360, 1, 3, 3]) || layers.2.residual_group.blocks.0.mlp.depthwise_conv.weight\n",
            " | -0.001 | -0.332 |  0.328 |  0.190 | torch.Size([360]) || layers.2.residual_group.blocks.0.mlp.depthwise_conv.bias\n",
            " | -0.000 | -0.082 |  0.082 |  0.020 | torch.Size([180, 360]) || layers.2.residual_group.blocks.0.mlp.fc2.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.0.mlp.fc2.bias\n",
            " | -15.972 | -100.000 |  0.000 | 36.635 | torch.Size([36, 64, 64]) || layers.2.residual_group.blocks.1.attn_mask\n",
            " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.1.norm1.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.1.norm1.bias\n",
            " |  0.000 | -0.082 |  0.081 |  0.020 | torch.Size([184, 180]) || layers.2.residual_group.blocks.1.attn.project_to_embed_dim.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.2.residual_group.blocks.1.attn.project_to_embed_dim.bias\n",
            " |  0.000 | -0.090 |  0.090 |  0.052 | torch.Size([552, 184]) || layers.2.residual_group.blocks.1.attn.multi_scale_attention.0.in_proj_weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([552]) || layers.2.residual_group.blocks.1.attn.multi_scale_attention.0.in_proj_bias\n",
            " | -0.000 | -0.092 |  0.072 |  0.020 | torch.Size([184, 184]) || layers.2.residual_group.blocks.1.attn.multi_scale_attention.0.out_proj.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.2.residual_group.blocks.1.attn.multi_scale_attention.0.out_proj.bias\n",
            " |  0.000 | -0.090 |  0.090 |  0.052 | torch.Size([552, 184]) || layers.2.residual_group.blocks.1.attn.multi_scale_attention.1.in_proj_weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([552]) || layers.2.residual_group.blocks.1.attn.multi_scale_attention.1.in_proj_bias\n",
            " |  0.000 | -0.089 |  0.088 |  0.020 | torch.Size([184, 184]) || layers.2.residual_group.blocks.1.attn.multi_scale_attention.1.out_proj.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.2.residual_group.blocks.1.attn.multi_scale_attention.1.out_proj.bias\n",
            " | -0.000 | -0.090 |  0.090 |  0.052 | torch.Size([552, 184]) || layers.2.residual_group.blocks.1.attn.multi_scale_attention.2.in_proj_weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([552]) || layers.2.residual_group.blocks.1.attn.multi_scale_attention.2.in_proj_bias\n",
            " | -0.000 | -0.087 |  0.085 |  0.020 | torch.Size([184, 184]) || layers.2.residual_group.blocks.1.attn.multi_scale_attention.2.out_proj.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.2.residual_group.blocks.1.attn.multi_scale_attention.2.out_proj.bias\n",
            " |  0.000 | -0.088 |  0.089 |  0.020 | torch.Size([180, 552]) || layers.2.residual_group.blocks.1.attn.fuse_fc.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.1.attn.fuse_fc.bias\n",
            " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.1.norm2.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.1.norm2.bias\n",
            " |  0.000 | -0.093 |  0.079 |  0.020 | torch.Size([360, 180]) || layers.2.residual_group.blocks.1.mlp.fc1.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.2.residual_group.blocks.1.mlp.fc1.bias\n",
            " |  0.000 | -0.333 |  0.333 |  0.193 | torch.Size([360, 1, 3, 3]) || layers.2.residual_group.blocks.1.mlp.depthwise_conv.weight\n",
            " |  0.008 | -0.331 |  0.330 |  0.193 | torch.Size([360]) || layers.2.residual_group.blocks.1.mlp.depthwise_conv.bias\n",
            " | -0.000 | -0.089 |  0.085 |  0.020 | torch.Size([180, 360]) || layers.2.residual_group.blocks.1.mlp.fc2.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.1.mlp.fc2.bias\n",
            " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.2.norm1.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.2.norm1.bias\n",
            " |  0.000 | -0.083 |  0.078 |  0.020 | torch.Size([184, 180]) || layers.2.residual_group.blocks.2.attn.project_to_embed_dim.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.2.residual_group.blocks.2.attn.project_to_embed_dim.bias\n",
            " | -0.000 | -0.090 |  0.090 |  0.052 | torch.Size([552, 184]) || layers.2.residual_group.blocks.2.attn.multi_scale_attention.0.in_proj_weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([552]) || layers.2.residual_group.blocks.2.attn.multi_scale_attention.0.in_proj_bias\n",
            " | -0.000 | -0.076 |  0.087 |  0.020 | torch.Size([184, 184]) || layers.2.residual_group.blocks.2.attn.multi_scale_attention.0.out_proj.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.2.residual_group.blocks.2.attn.multi_scale_attention.0.out_proj.bias\n",
            " |  0.000 | -0.090 |  0.090 |  0.052 | torch.Size([552, 184]) || layers.2.residual_group.blocks.2.attn.multi_scale_attention.1.in_proj_weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([552]) || layers.2.residual_group.blocks.2.attn.multi_scale_attention.1.in_proj_bias\n",
            " |  0.000 | -0.076 |  0.078 |  0.020 | torch.Size([184, 184]) || layers.2.residual_group.blocks.2.attn.multi_scale_attention.1.out_proj.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.2.residual_group.blocks.2.attn.multi_scale_attention.1.out_proj.bias\n",
            " |  0.000 | -0.090 |  0.090 |  0.052 | torch.Size([552, 184]) || layers.2.residual_group.blocks.2.attn.multi_scale_attention.2.in_proj_weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([552]) || layers.2.residual_group.blocks.2.attn.multi_scale_attention.2.in_proj_bias\n",
            " | -0.000 | -0.077 |  0.080 |  0.020 | torch.Size([184, 184]) || layers.2.residual_group.blocks.2.attn.multi_scale_attention.2.out_proj.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.2.residual_group.blocks.2.attn.multi_scale_attention.2.out_proj.bias\n",
            " |  0.000 | -0.093 |  0.084 |  0.020 | torch.Size([180, 552]) || layers.2.residual_group.blocks.2.attn.fuse_fc.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.2.attn.fuse_fc.bias\n",
            " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.2.norm2.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.2.norm2.bias\n",
            " | -0.000 | -0.081 |  0.095 |  0.020 | torch.Size([360, 180]) || layers.2.residual_group.blocks.2.mlp.fc1.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.2.residual_group.blocks.2.mlp.fc1.bias\n",
            " | -0.007 | -0.333 |  0.333 |  0.191 | torch.Size([360, 1, 3, 3]) || layers.2.residual_group.blocks.2.mlp.depthwise_conv.weight\n",
            " | -0.009 | -0.332 |  0.329 |  0.194 | torch.Size([360]) || layers.2.residual_group.blocks.2.mlp.depthwise_conv.bias\n",
            " |  0.000 | -0.085 |  0.083 |  0.020 | torch.Size([180, 360]) || layers.2.residual_group.blocks.2.mlp.fc2.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.2.mlp.fc2.bias\n",
            " | -15.972 | -100.000 |  0.000 | 36.635 | torch.Size([36, 64, 64]) || layers.2.residual_group.blocks.3.attn_mask\n",
            " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.3.norm1.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.3.norm1.bias\n",
            " |  0.000 | -0.083 |  0.071 |  0.020 | torch.Size([184, 180]) || layers.2.residual_group.blocks.3.attn.project_to_embed_dim.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.2.residual_group.blocks.3.attn.project_to_embed_dim.bias\n",
            " |  0.000 | -0.090 |  0.090 |  0.052 | torch.Size([552, 184]) || layers.2.residual_group.blocks.3.attn.multi_scale_attention.0.in_proj_weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([552]) || layers.2.residual_group.blocks.3.attn.multi_scale_attention.0.in_proj_bias\n",
            " |  0.000 | -0.079 |  0.085 |  0.020 | torch.Size([184, 184]) || layers.2.residual_group.blocks.3.attn.multi_scale_attention.0.out_proj.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.2.residual_group.blocks.3.attn.multi_scale_attention.0.out_proj.bias\n",
            " |  0.000 | -0.090 |  0.090 |  0.052 | torch.Size([552, 184]) || layers.2.residual_group.blocks.3.attn.multi_scale_attention.1.in_proj_weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([552]) || layers.2.residual_group.blocks.3.attn.multi_scale_attention.1.in_proj_bias\n",
            " | -0.000 | -0.085 |  0.080 |  0.020 | torch.Size([184, 184]) || layers.2.residual_group.blocks.3.attn.multi_scale_attention.1.out_proj.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.2.residual_group.blocks.3.attn.multi_scale_attention.1.out_proj.bias\n",
            " | -0.000 | -0.090 |  0.090 |  0.052 | torch.Size([552, 184]) || layers.2.residual_group.blocks.3.attn.multi_scale_attention.2.in_proj_weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([552]) || layers.2.residual_group.blocks.3.attn.multi_scale_attention.2.in_proj_bias\n",
            " |  0.000 | -0.084 |  0.098 |  0.020 | torch.Size([184, 184]) || layers.2.residual_group.blocks.3.attn.multi_scale_attention.2.out_proj.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.2.residual_group.blocks.3.attn.multi_scale_attention.2.out_proj.bias\n",
            " |  0.000 | -0.082 |  0.084 |  0.020 | torch.Size([180, 552]) || layers.2.residual_group.blocks.3.attn.fuse_fc.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.3.attn.fuse_fc.bias\n",
            " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.3.norm2.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.3.norm2.bias\n",
            " |  0.000 | -0.093 |  0.082 |  0.020 | torch.Size([360, 180]) || layers.2.residual_group.blocks.3.mlp.fc1.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.2.residual_group.blocks.3.mlp.fc1.bias\n",
            " | -0.006 | -0.333 |  0.333 |  0.195 | torch.Size([360, 1, 3, 3]) || layers.2.residual_group.blocks.3.mlp.depthwise_conv.weight\n",
            " |  0.003 | -0.333 |  0.333 |  0.191 | torch.Size([360]) || layers.2.residual_group.blocks.3.mlp.depthwise_conv.bias\n",
            " | -0.000 | -0.080 |  0.084 |  0.020 | torch.Size([180, 360]) || layers.2.residual_group.blocks.3.mlp.fc2.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.3.mlp.fc2.bias\n",
            " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.4.norm1.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.4.norm1.bias\n",
            " | -0.000 | -0.080 |  0.080 |  0.020 | torch.Size([184, 180]) || layers.2.residual_group.blocks.4.attn.project_to_embed_dim.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.2.residual_group.blocks.4.attn.project_to_embed_dim.bias\n",
            " | -0.000 | -0.090 |  0.090 |  0.052 | torch.Size([552, 184]) || layers.2.residual_group.blocks.4.attn.multi_scale_attention.0.in_proj_weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([552]) || layers.2.residual_group.blocks.4.attn.multi_scale_attention.0.in_proj_bias\n",
            " |  0.000 | -0.083 |  0.096 |  0.020 | torch.Size([184, 184]) || layers.2.residual_group.blocks.4.attn.multi_scale_attention.0.out_proj.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.2.residual_group.blocks.4.attn.multi_scale_attention.0.out_proj.bias\n",
            " |  0.000 | -0.090 |  0.090 |  0.052 | torch.Size([552, 184]) || layers.2.residual_group.blocks.4.attn.multi_scale_attention.1.in_proj_weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([552]) || layers.2.residual_group.blocks.4.attn.multi_scale_attention.1.in_proj_bias\n",
            " | -0.000 | -0.083 |  0.086 |  0.020 | torch.Size([184, 184]) || layers.2.residual_group.blocks.4.attn.multi_scale_attention.1.out_proj.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.2.residual_group.blocks.4.attn.multi_scale_attention.1.out_proj.bias\n",
            " |  0.000 | -0.090 |  0.090 |  0.052 | torch.Size([552, 184]) || layers.2.residual_group.blocks.4.attn.multi_scale_attention.2.in_proj_weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([552]) || layers.2.residual_group.blocks.4.attn.multi_scale_attention.2.in_proj_bias\n",
            " | -0.000 | -0.083 |  0.076 |  0.020 | torch.Size([184, 184]) || layers.2.residual_group.blocks.4.attn.multi_scale_attention.2.out_proj.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.2.residual_group.blocks.4.attn.multi_scale_attention.2.out_proj.bias\n",
            " |  0.000 | -0.092 |  0.087 |  0.020 | torch.Size([180, 552]) || layers.2.residual_group.blocks.4.attn.fuse_fc.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.4.attn.fuse_fc.bias\n",
            " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.4.norm2.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.4.norm2.bias\n",
            " |  0.000 | -0.089 |  0.090 |  0.020 | torch.Size([360, 180]) || layers.2.residual_group.blocks.4.mlp.fc1.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.2.residual_group.blocks.4.mlp.fc1.bias\n",
            " | -0.002 | -0.333 |  0.333 |  0.192 | torch.Size([360, 1, 3, 3]) || layers.2.residual_group.blocks.4.mlp.depthwise_conv.weight\n",
            " | -0.001 | -0.331 |  0.330 |  0.192 | torch.Size([360]) || layers.2.residual_group.blocks.4.mlp.depthwise_conv.bias\n",
            " |  0.000 | -0.078 |  0.084 |  0.020 | torch.Size([180, 360]) || layers.2.residual_group.blocks.4.mlp.fc2.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.4.mlp.fc2.bias\n",
            " | -15.972 | -100.000 |  0.000 | 36.635 | torch.Size([36, 64, 64]) || layers.2.residual_group.blocks.5.attn_mask\n",
            " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.5.norm1.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.5.norm1.bias\n",
            " | -0.000 | -0.080 |  0.086 |  0.020 | torch.Size([184, 180]) || layers.2.residual_group.blocks.5.attn.project_to_embed_dim.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.2.residual_group.blocks.5.attn.project_to_embed_dim.bias\n",
            " |  0.000 | -0.090 |  0.090 |  0.052 | torch.Size([552, 184]) || layers.2.residual_group.blocks.5.attn.multi_scale_attention.0.in_proj_weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([552]) || layers.2.residual_group.blocks.5.attn.multi_scale_attention.0.in_proj_bias\n",
            " | -0.000 | -0.074 |  0.081 |  0.020 | torch.Size([184, 184]) || layers.2.residual_group.blocks.5.attn.multi_scale_attention.0.out_proj.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.2.residual_group.blocks.5.attn.multi_scale_attention.0.out_proj.bias\n",
            " | -0.000 | -0.090 |  0.090 |  0.052 | torch.Size([552, 184]) || layers.2.residual_group.blocks.5.attn.multi_scale_attention.1.in_proj_weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([552]) || layers.2.residual_group.blocks.5.attn.multi_scale_attention.1.in_proj_bias\n",
            " | -0.000 | -0.086 |  0.086 |  0.020 | torch.Size([184, 184]) || layers.2.residual_group.blocks.5.attn.multi_scale_attention.1.out_proj.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.2.residual_group.blocks.5.attn.multi_scale_attention.1.out_proj.bias\n",
            " | -0.000 | -0.090 |  0.090 |  0.052 | torch.Size([552, 184]) || layers.2.residual_group.blocks.5.attn.multi_scale_attention.2.in_proj_weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([552]) || layers.2.residual_group.blocks.5.attn.multi_scale_attention.2.in_proj_bias\n",
            " |  0.000 | -0.088 |  0.080 |  0.020 | torch.Size([184, 184]) || layers.2.residual_group.blocks.5.attn.multi_scale_attention.2.out_proj.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.2.residual_group.blocks.5.attn.multi_scale_attention.2.out_proj.bias\n",
            " |  0.000 | -0.083 |  0.087 |  0.020 | torch.Size([180, 552]) || layers.2.residual_group.blocks.5.attn.fuse_fc.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.5.attn.fuse_fc.bias\n",
            " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.5.norm2.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.5.norm2.bias\n",
            " | -0.000 | -0.091 |  0.087 |  0.020 | torch.Size([360, 180]) || layers.2.residual_group.blocks.5.mlp.fc1.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.2.residual_group.blocks.5.mlp.fc1.bias\n",
            " | -0.005 | -0.333 |  0.333 |  0.192 | torch.Size([360, 1, 3, 3]) || layers.2.residual_group.blocks.5.mlp.depthwise_conv.weight\n",
            " | -0.012 | -0.333 |  0.333 |  0.193 | torch.Size([360]) || layers.2.residual_group.blocks.5.mlp.depthwise_conv.bias\n",
            " |  0.000 | -0.090 |  0.082 |  0.020 | torch.Size([180, 360]) || layers.2.residual_group.blocks.5.mlp.fc2.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.5.mlp.fc2.bias\n",
            " |  0.000 | -0.011 |  0.011 |  0.006 | torch.Size([1, 180, 7, 7]) || layers.2.attn_module.spatial_attention.0.weight\n",
            " | -0.000 | -0.000 | -0.000 |    nan | torch.Size([1]) || layers.2.attn_module.spatial_attention.0.bias\n",
            " | -0.000 | -0.075 |  0.075 |  0.043 | torch.Size([22, 180, 1, 1]) || layers.2.attn_module.channel_attention.1.weight\n",
            " | -0.002 | -0.074 |  0.074 |  0.051 | torch.Size([22]) || layers.2.attn_module.channel_attention.1.bias\n",
            " | -0.000 | -0.213 |  0.213 |  0.122 | torch.Size([180, 22, 1, 1]) || layers.2.attn_module.channel_attention.3.weight\n",
            " |  0.003 | -0.210 |  0.211 |  0.115 | torch.Size([180]) || layers.2.attn_module.channel_attention.3.bias\n",
            " | -0.000 | -0.025 |  0.025 |  0.014 | torch.Size([180, 180, 3, 3]) || layers.2.conv.weight\n",
            " |  0.000 | -0.025 |  0.025 |  0.014 | torch.Size([180]) || layers.2.conv.bias\n",
            " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.0.norm1.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.0.norm1.bias\n",
            " |  0.000 | -0.081 |  0.080 |  0.020 | torch.Size([184, 180]) || layers.3.residual_group.blocks.0.attn.project_to_embed_dim.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.3.residual_group.blocks.0.attn.project_to_embed_dim.bias\n",
            " |  0.000 | -0.090 |  0.090 |  0.052 | torch.Size([552, 184]) || layers.3.residual_group.blocks.0.attn.multi_scale_attention.0.in_proj_weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([552]) || layers.3.residual_group.blocks.0.attn.multi_scale_attention.0.in_proj_bias\n",
            " |  0.000 | -0.086 |  0.080 |  0.020 | torch.Size([184, 184]) || layers.3.residual_group.blocks.0.attn.multi_scale_attention.0.out_proj.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.3.residual_group.blocks.0.attn.multi_scale_attention.0.out_proj.bias\n",
            " | -0.000 | -0.090 |  0.090 |  0.052 | torch.Size([552, 184]) || layers.3.residual_group.blocks.0.attn.multi_scale_attention.1.in_proj_weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([552]) || layers.3.residual_group.blocks.0.attn.multi_scale_attention.1.in_proj_bias\n",
            " | -0.000 | -0.088 |  0.086 |  0.020 | torch.Size([184, 184]) || layers.3.residual_group.blocks.0.attn.multi_scale_attention.1.out_proj.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.3.residual_group.blocks.0.attn.multi_scale_attention.1.out_proj.bias\n",
            " |  0.000 | -0.090 |  0.090 |  0.052 | torch.Size([552, 184]) || layers.3.residual_group.blocks.0.attn.multi_scale_attention.2.in_proj_weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([552]) || layers.3.residual_group.blocks.0.attn.multi_scale_attention.2.in_proj_bias\n",
            " |  0.000 | -0.080 |  0.077 |  0.020 | torch.Size([184, 184]) || layers.3.residual_group.blocks.0.attn.multi_scale_attention.2.out_proj.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.3.residual_group.blocks.0.attn.multi_scale_attention.2.out_proj.bias\n",
            " | -0.000 | -0.080 |  0.088 |  0.020 | torch.Size([180, 552]) || layers.3.residual_group.blocks.0.attn.fuse_fc.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.0.attn.fuse_fc.bias\n",
            " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.0.norm2.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.0.norm2.bias\n",
            " | -0.000 | -0.092 |  0.093 |  0.020 | torch.Size([360, 180]) || layers.3.residual_group.blocks.0.mlp.fc1.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.3.residual_group.blocks.0.mlp.fc1.bias\n",
            " | -0.000 | -0.333 |  0.333 |  0.194 | torch.Size([360, 1, 3, 3]) || layers.3.residual_group.blocks.0.mlp.depthwise_conv.weight\n",
            " |  0.007 | -0.329 |  0.331 |  0.191 | torch.Size([360]) || layers.3.residual_group.blocks.0.mlp.depthwise_conv.bias\n",
            " | -0.000 | -0.085 |  0.094 |  0.020 | torch.Size([180, 360]) || layers.3.residual_group.blocks.0.mlp.fc2.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.0.mlp.fc2.bias\n",
            " | -15.972 | -100.000 |  0.000 | 36.635 | torch.Size([36, 64, 64]) || layers.3.residual_group.blocks.1.attn_mask\n",
            " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.1.norm1.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.1.norm1.bias\n",
            " | -0.000 | -0.085 |  0.096 |  0.020 | torch.Size([184, 180]) || layers.3.residual_group.blocks.1.attn.project_to_embed_dim.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.3.residual_group.blocks.1.attn.project_to_embed_dim.bias\n",
            " | -0.000 | -0.090 |  0.090 |  0.052 | torch.Size([552, 184]) || layers.3.residual_group.blocks.1.attn.multi_scale_attention.0.in_proj_weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([552]) || layers.3.residual_group.blocks.1.attn.multi_scale_attention.0.in_proj_bias\n",
            " |  0.000 | -0.081 |  0.076 |  0.020 | torch.Size([184, 184]) || layers.3.residual_group.blocks.1.attn.multi_scale_attention.0.out_proj.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.3.residual_group.blocks.1.attn.multi_scale_attention.0.out_proj.bias\n",
            " | -0.000 | -0.090 |  0.090 |  0.052 | torch.Size([552, 184]) || layers.3.residual_group.blocks.1.attn.multi_scale_attention.1.in_proj_weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([552]) || layers.3.residual_group.blocks.1.attn.multi_scale_attention.1.in_proj_bias\n",
            " | -0.000 | -0.084 |  0.083 |  0.020 | torch.Size([184, 184]) || layers.3.residual_group.blocks.1.attn.multi_scale_attention.1.out_proj.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.3.residual_group.blocks.1.attn.multi_scale_attention.1.out_proj.bias\n",
            " |  0.000 | -0.090 |  0.090 |  0.052 | torch.Size([552, 184]) || layers.3.residual_group.blocks.1.attn.multi_scale_attention.2.in_proj_weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([552]) || layers.3.residual_group.blocks.1.attn.multi_scale_attention.2.in_proj_bias\n",
            " | -0.000 | -0.086 |  0.083 |  0.020 | torch.Size([184, 184]) || layers.3.residual_group.blocks.1.attn.multi_scale_attention.2.out_proj.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.3.residual_group.blocks.1.attn.multi_scale_attention.2.out_proj.bias\n",
            " | -0.000 | -0.091 |  0.092 |  0.020 | torch.Size([180, 552]) || layers.3.residual_group.blocks.1.attn.fuse_fc.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.1.attn.fuse_fc.bias\n",
            " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.1.norm2.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.1.norm2.bias\n",
            " |  0.000 | -0.103 |  0.094 |  0.020 | torch.Size([360, 180]) || layers.3.residual_group.blocks.1.mlp.fc1.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.3.residual_group.blocks.1.mlp.fc1.bias\n",
            " | -0.002 | -0.333 |  0.333 |  0.194 | torch.Size([360, 1, 3, 3]) || layers.3.residual_group.blocks.1.mlp.depthwise_conv.weight\n",
            " |  0.000 | -0.331 |  0.333 |  0.193 | torch.Size([360]) || layers.3.residual_group.blocks.1.mlp.depthwise_conv.bias\n",
            " |  0.000 | -0.081 |  0.095 |  0.020 | torch.Size([180, 360]) || layers.3.residual_group.blocks.1.mlp.fc2.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.1.mlp.fc2.bias\n",
            " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.2.norm1.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.2.norm1.bias\n",
            " | -0.000 | -0.091 |  0.078 |  0.020 | torch.Size([184, 180]) || layers.3.residual_group.blocks.2.attn.project_to_embed_dim.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.3.residual_group.blocks.2.attn.project_to_embed_dim.bias\n",
            " | -0.000 | -0.090 |  0.090 |  0.052 | torch.Size([552, 184]) || layers.3.residual_group.blocks.2.attn.multi_scale_attention.0.in_proj_weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([552]) || layers.3.residual_group.blocks.2.attn.multi_scale_attention.0.in_proj_bias\n",
            " | -0.000 | -0.092 |  0.080 |  0.020 | torch.Size([184, 184]) || layers.3.residual_group.blocks.2.attn.multi_scale_attention.0.out_proj.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.3.residual_group.blocks.2.attn.multi_scale_attention.0.out_proj.bias\n",
            " | -0.000 | -0.090 |  0.090 |  0.052 | torch.Size([552, 184]) || layers.3.residual_group.blocks.2.attn.multi_scale_attention.1.in_proj_weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([552]) || layers.3.residual_group.blocks.2.attn.multi_scale_attention.1.in_proj_bias\n",
            " |  0.000 | -0.089 |  0.079 |  0.020 | torch.Size([184, 184]) || layers.3.residual_group.blocks.2.attn.multi_scale_attention.1.out_proj.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.3.residual_group.blocks.2.attn.multi_scale_attention.1.out_proj.bias\n",
            " | -0.000 | -0.090 |  0.090 |  0.052 | torch.Size([552, 184]) || layers.3.residual_group.blocks.2.attn.multi_scale_attention.2.in_proj_weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([552]) || layers.3.residual_group.blocks.2.attn.multi_scale_attention.2.in_proj_bias\n",
            " | -0.000 | -0.078 |  0.090 |  0.020 | torch.Size([184, 184]) || layers.3.residual_group.blocks.2.attn.multi_scale_attention.2.out_proj.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.3.residual_group.blocks.2.attn.multi_scale_attention.2.out_proj.bias\n",
            " | -0.000 | -0.095 |  0.087 |  0.020 | torch.Size([180, 552]) || layers.3.residual_group.blocks.2.attn.fuse_fc.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.2.attn.fuse_fc.bias\n",
            " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.2.norm2.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.2.norm2.bias\n",
            " |  0.000 | -0.091 |  0.079 |  0.020 | torch.Size([360, 180]) || layers.3.residual_group.blocks.2.mlp.fc1.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.3.residual_group.blocks.2.mlp.fc1.bias\n",
            " |  0.002 | -0.333 |  0.333 |  0.193 | torch.Size([360, 1, 3, 3]) || layers.3.residual_group.blocks.2.mlp.depthwise_conv.weight\n",
            " | -0.006 | -0.332 |  0.331 |  0.202 | torch.Size([360]) || layers.3.residual_group.blocks.2.mlp.depthwise_conv.bias\n",
            " |  0.000 | -0.082 |  0.080 |  0.020 | torch.Size([180, 360]) || layers.3.residual_group.blocks.2.mlp.fc2.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.2.mlp.fc2.bias\n",
            " | -15.972 | -100.000 |  0.000 | 36.635 | torch.Size([36, 64, 64]) || layers.3.residual_group.blocks.3.attn_mask\n",
            " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.3.norm1.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.3.norm1.bias\n",
            " |  0.000 | -0.079 |  0.077 |  0.020 | torch.Size([184, 180]) || layers.3.residual_group.blocks.3.attn.project_to_embed_dim.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.3.residual_group.blocks.3.attn.project_to_embed_dim.bias\n",
            " |  0.000 | -0.090 |  0.090 |  0.052 | torch.Size([552, 184]) || layers.3.residual_group.blocks.3.attn.multi_scale_attention.0.in_proj_weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([552]) || layers.3.residual_group.blocks.3.attn.multi_scale_attention.0.in_proj_bias\n",
            " | -0.000 | -0.076 |  0.076 |  0.020 | torch.Size([184, 184]) || layers.3.residual_group.blocks.3.attn.multi_scale_attention.0.out_proj.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.3.residual_group.blocks.3.attn.multi_scale_attention.0.out_proj.bias\n",
            " | -0.000 | -0.090 |  0.090 |  0.052 | torch.Size([552, 184]) || layers.3.residual_group.blocks.3.attn.multi_scale_attention.1.in_proj_weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([552]) || layers.3.residual_group.blocks.3.attn.multi_scale_attention.1.in_proj_bias\n",
            " | -0.000 | -0.076 |  0.081 |  0.020 | torch.Size([184, 184]) || layers.3.residual_group.blocks.3.attn.multi_scale_attention.1.out_proj.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.3.residual_group.blocks.3.attn.multi_scale_attention.1.out_proj.bias\n",
            " |  0.000 | -0.090 |  0.090 |  0.052 | torch.Size([552, 184]) || layers.3.residual_group.blocks.3.attn.multi_scale_attention.2.in_proj_weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([552]) || layers.3.residual_group.blocks.3.attn.multi_scale_attention.2.in_proj_bias\n",
            " |  0.000 | -0.078 |  0.083 |  0.020 | torch.Size([184, 184]) || layers.3.residual_group.blocks.3.attn.multi_scale_attention.2.out_proj.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.3.residual_group.blocks.3.attn.multi_scale_attention.2.out_proj.bias\n",
            " |  0.000 | -0.083 |  0.106 |  0.020 | torch.Size([180, 552]) || layers.3.residual_group.blocks.3.attn.fuse_fc.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.3.attn.fuse_fc.bias\n",
            " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.3.norm2.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.3.norm2.bias\n",
            " | -0.000 | -0.087 |  0.088 |  0.020 | torch.Size([360, 180]) || layers.3.residual_group.blocks.3.mlp.fc1.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.3.residual_group.blocks.3.mlp.fc1.bias\n",
            " | -0.007 | -0.333 |  0.333 |  0.193 | torch.Size([360, 1, 3, 3]) || layers.3.residual_group.blocks.3.mlp.depthwise_conv.weight\n",
            " | -0.008 | -0.332 |  0.331 |  0.198 | torch.Size([360]) || layers.3.residual_group.blocks.3.mlp.depthwise_conv.bias\n",
            " | -0.000 | -0.085 |  0.080 |  0.020 | torch.Size([180, 360]) || layers.3.residual_group.blocks.3.mlp.fc2.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.3.mlp.fc2.bias\n",
            " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.4.norm1.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.4.norm1.bias\n",
            " | -0.000 | -0.078 |  0.085 |  0.020 | torch.Size([184, 180]) || layers.3.residual_group.blocks.4.attn.project_to_embed_dim.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.3.residual_group.blocks.4.attn.project_to_embed_dim.bias\n",
            " | -0.000 | -0.090 |  0.090 |  0.052 | torch.Size([552, 184]) || layers.3.residual_group.blocks.4.attn.multi_scale_attention.0.in_proj_weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([552]) || layers.3.residual_group.blocks.4.attn.multi_scale_attention.0.in_proj_bias\n",
            " |  0.000 | -0.084 |  0.089 |  0.020 | torch.Size([184, 184]) || layers.3.residual_group.blocks.4.attn.multi_scale_attention.0.out_proj.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.3.residual_group.blocks.4.attn.multi_scale_attention.0.out_proj.bias\n",
            " |  0.000 | -0.090 |  0.090 |  0.052 | torch.Size([552, 184]) || layers.3.residual_group.blocks.4.attn.multi_scale_attention.1.in_proj_weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([552]) || layers.3.residual_group.blocks.4.attn.multi_scale_attention.1.in_proj_bias\n",
            " | -0.000 | -0.083 |  0.092 |  0.020 | torch.Size([184, 184]) || layers.3.residual_group.blocks.4.attn.multi_scale_attention.1.out_proj.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.3.residual_group.blocks.4.attn.multi_scale_attention.1.out_proj.bias\n",
            " | -0.000 | -0.090 |  0.090 |  0.052 | torch.Size([552, 184]) || layers.3.residual_group.blocks.4.attn.multi_scale_attention.2.in_proj_weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([552]) || layers.3.residual_group.blocks.4.attn.multi_scale_attention.2.in_proj_bias\n",
            " | -0.000 | -0.081 |  0.073 |  0.020 | torch.Size([184, 184]) || layers.3.residual_group.blocks.4.attn.multi_scale_attention.2.out_proj.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.3.residual_group.blocks.4.attn.multi_scale_attention.2.out_proj.bias\n",
            " |  0.000 | -0.086 |  0.091 |  0.020 | torch.Size([180, 552]) || layers.3.residual_group.blocks.4.attn.fuse_fc.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.4.attn.fuse_fc.bias\n",
            " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.4.norm2.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.4.norm2.bias\n",
            " | -0.000 | -0.086 |  0.082 |  0.020 | torch.Size([360, 180]) || layers.3.residual_group.blocks.4.mlp.fc1.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.3.residual_group.blocks.4.mlp.fc1.bias\n",
            " |  0.001 | -0.333 |  0.333 |  0.193 | torch.Size([360, 1, 3, 3]) || layers.3.residual_group.blocks.4.mlp.depthwise_conv.weight\n",
            " | -0.001 | -0.331 |  0.331 |  0.189 | torch.Size([360]) || layers.3.residual_group.blocks.4.mlp.depthwise_conv.bias\n",
            " |  0.000 | -0.092 |  0.087 |  0.020 | torch.Size([180, 360]) || layers.3.residual_group.blocks.4.mlp.fc2.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.4.mlp.fc2.bias\n",
            " | -15.972 | -100.000 |  0.000 | 36.635 | torch.Size([36, 64, 64]) || layers.3.residual_group.blocks.5.attn_mask\n",
            " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.5.norm1.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.5.norm1.bias\n",
            " | -0.000 | -0.090 |  0.083 |  0.020 | torch.Size([184, 180]) || layers.3.residual_group.blocks.5.attn.project_to_embed_dim.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.3.residual_group.blocks.5.attn.project_to_embed_dim.bias\n",
            " | -0.000 | -0.090 |  0.090 |  0.052 | torch.Size([552, 184]) || layers.3.residual_group.blocks.5.attn.multi_scale_attention.0.in_proj_weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([552]) || layers.3.residual_group.blocks.5.attn.multi_scale_attention.0.in_proj_bias\n",
            " | -0.000 | -0.078 |  0.079 |  0.020 | torch.Size([184, 184]) || layers.3.residual_group.blocks.5.attn.multi_scale_attention.0.out_proj.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.3.residual_group.blocks.5.attn.multi_scale_attention.0.out_proj.bias\n",
            " | -0.000 | -0.090 |  0.090 |  0.052 | torch.Size([552, 184]) || layers.3.residual_group.blocks.5.attn.multi_scale_attention.1.in_proj_weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([552]) || layers.3.residual_group.blocks.5.attn.multi_scale_attention.1.in_proj_bias\n",
            " | -0.000 | -0.080 |  0.077 |  0.020 | torch.Size([184, 184]) || layers.3.residual_group.blocks.5.attn.multi_scale_attention.1.out_proj.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.3.residual_group.blocks.5.attn.multi_scale_attention.1.out_proj.bias\n",
            " | -0.000 | -0.090 |  0.090 |  0.052 | torch.Size([552, 184]) || layers.3.residual_group.blocks.5.attn.multi_scale_attention.2.in_proj_weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([552]) || layers.3.residual_group.blocks.5.attn.multi_scale_attention.2.in_proj_bias\n",
            " |  0.000 | -0.078 |  0.086 |  0.020 | torch.Size([184, 184]) || layers.3.residual_group.blocks.5.attn.multi_scale_attention.2.out_proj.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.3.residual_group.blocks.5.attn.multi_scale_attention.2.out_proj.bias\n",
            " | -0.000 | -0.093 |  0.085 |  0.020 | torch.Size([180, 552]) || layers.3.residual_group.blocks.5.attn.fuse_fc.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.5.attn.fuse_fc.bias\n",
            " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.5.norm2.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.5.norm2.bias\n",
            " |  0.000 | -0.082 |  0.083 |  0.020 | torch.Size([360, 180]) || layers.3.residual_group.blocks.5.mlp.fc1.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.3.residual_group.blocks.5.mlp.fc1.bias\n",
            " | -0.003 | -0.333 |  0.333 |  0.192 | torch.Size([360, 1, 3, 3]) || layers.3.residual_group.blocks.5.mlp.depthwise_conv.weight\n",
            " | -0.003 | -0.333 |  0.333 |  0.194 | torch.Size([360]) || layers.3.residual_group.blocks.5.mlp.depthwise_conv.bias\n",
            " | -0.000 | -0.085 |  0.083 |  0.020 | torch.Size([180, 360]) || layers.3.residual_group.blocks.5.mlp.fc2.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.5.mlp.fc2.bias\n",
            " | -0.000 | -0.011 |  0.011 |  0.006 | torch.Size([1, 180, 7, 7]) || layers.3.attn_module.spatial_attention.0.weight\n",
            " |  0.008 |  0.008 |  0.008 |    nan | torch.Size([1]) || layers.3.attn_module.spatial_attention.0.bias\n",
            " | -0.000 | -0.074 |  0.075 |  0.043 | torch.Size([22, 180, 1, 1]) || layers.3.attn_module.channel_attention.1.weight\n",
            " |  0.010 | -0.065 |  0.071 |  0.042 | torch.Size([22]) || layers.3.attn_module.channel_attention.1.bias\n",
            " | -0.001 | -0.213 |  0.213 |  0.123 | torch.Size([180, 22, 1, 1]) || layers.3.attn_module.channel_attention.3.weight\n",
            " |  0.005 | -0.209 |  0.213 |  0.122 | torch.Size([180]) || layers.3.attn_module.channel_attention.3.bias\n",
            " | -0.000 | -0.025 |  0.025 |  0.014 | torch.Size([180, 180, 3, 3]) || layers.3.conv.weight\n",
            " |  0.002 | -0.025 |  0.024 |  0.015 | torch.Size([180]) || layers.3.conv.bias\n",
            " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.0.norm1.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.0.norm1.bias\n",
            " |  0.000 | -0.083 |  0.085 |  0.020 | torch.Size([184, 180]) || layers.4.residual_group.blocks.0.attn.project_to_embed_dim.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.4.residual_group.blocks.0.attn.project_to_embed_dim.bias\n",
            " |  0.000 | -0.090 |  0.090 |  0.052 | torch.Size([552, 184]) || layers.4.residual_group.blocks.0.attn.multi_scale_attention.0.in_proj_weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([552]) || layers.4.residual_group.blocks.0.attn.multi_scale_attention.0.in_proj_bias\n",
            " | -0.000 | -0.094 |  0.076 |  0.020 | torch.Size([184, 184]) || layers.4.residual_group.blocks.0.attn.multi_scale_attention.0.out_proj.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.4.residual_group.blocks.0.attn.multi_scale_attention.0.out_proj.bias\n",
            " | -0.000 | -0.090 |  0.090 |  0.052 | torch.Size([552, 184]) || layers.4.residual_group.blocks.0.attn.multi_scale_attention.1.in_proj_weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([552]) || layers.4.residual_group.blocks.0.attn.multi_scale_attention.1.in_proj_bias\n",
            " |  0.000 | -0.085 |  0.086 |  0.020 | torch.Size([184, 184]) || layers.4.residual_group.blocks.0.attn.multi_scale_attention.1.out_proj.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.4.residual_group.blocks.0.attn.multi_scale_attention.1.out_proj.bias\n",
            " |  0.000 | -0.090 |  0.090 |  0.052 | torch.Size([552, 184]) || layers.4.residual_group.blocks.0.attn.multi_scale_attention.2.in_proj_weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([552]) || layers.4.residual_group.blocks.0.attn.multi_scale_attention.2.in_proj_bias\n",
            " | -0.000 | -0.077 |  0.089 |  0.020 | torch.Size([184, 184]) || layers.4.residual_group.blocks.0.attn.multi_scale_attention.2.out_proj.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.4.residual_group.blocks.0.attn.multi_scale_attention.2.out_proj.bias\n",
            " | -0.000 | -0.088 |  0.091 |  0.020 | torch.Size([180, 552]) || layers.4.residual_group.blocks.0.attn.fuse_fc.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.0.attn.fuse_fc.bias\n",
            " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.0.norm2.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.0.norm2.bias\n",
            " | -0.000 | -0.078 |  0.096 |  0.020 | torch.Size([360, 180]) || layers.4.residual_group.blocks.0.mlp.fc1.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.4.residual_group.blocks.0.mlp.fc1.bias\n",
            " |  0.010 | -0.333 |  0.333 |  0.195 | torch.Size([360, 1, 3, 3]) || layers.4.residual_group.blocks.0.mlp.depthwise_conv.weight\n",
            " |  0.005 | -0.328 |  0.332 |  0.188 | torch.Size([360]) || layers.4.residual_group.blocks.0.mlp.depthwise_conv.bias\n",
            " | -0.000 | -0.083 |  0.089 |  0.020 | torch.Size([180, 360]) || layers.4.residual_group.blocks.0.mlp.fc2.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.0.mlp.fc2.bias\n",
            " | -15.972 | -100.000 |  0.000 | 36.635 | torch.Size([36, 64, 64]) || layers.4.residual_group.blocks.1.attn_mask\n",
            " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.1.norm1.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.1.norm1.bias\n",
            " |  0.000 | -0.084 |  0.096 |  0.020 | torch.Size([184, 180]) || layers.4.residual_group.blocks.1.attn.project_to_embed_dim.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.4.residual_group.blocks.1.attn.project_to_embed_dim.bias\n",
            " |  0.000 | -0.090 |  0.090 |  0.052 | torch.Size([552, 184]) || layers.4.residual_group.blocks.1.attn.multi_scale_attention.0.in_proj_weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([552]) || layers.4.residual_group.blocks.1.attn.multi_scale_attention.0.in_proj_bias\n",
            " |  0.000 | -0.076 |  0.086 |  0.020 | torch.Size([184, 184]) || layers.4.residual_group.blocks.1.attn.multi_scale_attention.0.out_proj.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.4.residual_group.blocks.1.attn.multi_scale_attention.0.out_proj.bias\n",
            " | -0.000 | -0.090 |  0.090 |  0.052 | torch.Size([552, 184]) || layers.4.residual_group.blocks.1.attn.multi_scale_attention.1.in_proj_weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([552]) || layers.4.residual_group.blocks.1.attn.multi_scale_attention.1.in_proj_bias\n",
            " |  0.000 | -0.082 |  0.076 |  0.020 | torch.Size([184, 184]) || layers.4.residual_group.blocks.1.attn.multi_scale_attention.1.out_proj.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.4.residual_group.blocks.1.attn.multi_scale_attention.1.out_proj.bias\n",
            " |  0.000 | -0.090 |  0.090 |  0.052 | torch.Size([552, 184]) || layers.4.residual_group.blocks.1.attn.multi_scale_attention.2.in_proj_weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([552]) || layers.4.residual_group.blocks.1.attn.multi_scale_attention.2.in_proj_bias\n",
            " |  0.000 | -0.078 |  0.080 |  0.020 | torch.Size([184, 184]) || layers.4.residual_group.blocks.1.attn.multi_scale_attention.2.out_proj.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.4.residual_group.blocks.1.attn.multi_scale_attention.2.out_proj.bias\n",
            " |  0.000 | -0.085 |  0.093 |  0.020 | torch.Size([180, 552]) || layers.4.residual_group.blocks.1.attn.fuse_fc.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.1.attn.fuse_fc.bias\n",
            " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.1.norm2.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.1.norm2.bias\n",
            " | -0.000 | -0.084 |  0.091 |  0.020 | torch.Size([360, 180]) || layers.4.residual_group.blocks.1.mlp.fc1.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.4.residual_group.blocks.1.mlp.fc1.bias\n",
            " | -0.002 | -0.333 |  0.333 |  0.193 | torch.Size([360, 1, 3, 3]) || layers.4.residual_group.blocks.1.mlp.depthwise_conv.weight\n",
            " |  0.007 | -0.331 |  0.329 |  0.194 | torch.Size([360]) || layers.4.residual_group.blocks.1.mlp.depthwise_conv.bias\n",
            " |  0.000 | -0.086 |  0.082 |  0.020 | torch.Size([180, 360]) || layers.4.residual_group.blocks.1.mlp.fc2.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.1.mlp.fc2.bias\n",
            " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.2.norm1.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.2.norm1.bias\n",
            " | -0.000 | -0.091 |  0.078 |  0.020 | torch.Size([184, 180]) || layers.4.residual_group.blocks.2.attn.project_to_embed_dim.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.4.residual_group.blocks.2.attn.project_to_embed_dim.bias\n",
            " |  0.000 | -0.090 |  0.090 |  0.052 | torch.Size([552, 184]) || layers.4.residual_group.blocks.2.attn.multi_scale_attention.0.in_proj_weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([552]) || layers.4.residual_group.blocks.2.attn.multi_scale_attention.0.in_proj_bias\n",
            " |  0.000 | -0.081 |  0.075 |  0.020 | torch.Size([184, 184]) || layers.4.residual_group.blocks.2.attn.multi_scale_attention.0.out_proj.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.4.residual_group.blocks.2.attn.multi_scale_attention.0.out_proj.bias\n",
            " | -0.000 | -0.090 |  0.090 |  0.052 | torch.Size([552, 184]) || layers.4.residual_group.blocks.2.attn.multi_scale_attention.1.in_proj_weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([552]) || layers.4.residual_group.blocks.2.attn.multi_scale_attention.1.in_proj_bias\n",
            " | -0.000 | -0.078 |  0.077 |  0.020 | torch.Size([184, 184]) || layers.4.residual_group.blocks.2.attn.multi_scale_attention.1.out_proj.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.4.residual_group.blocks.2.attn.multi_scale_attention.1.out_proj.bias\n",
            " | -0.000 | -0.090 |  0.090 |  0.052 | torch.Size([552, 184]) || layers.4.residual_group.blocks.2.attn.multi_scale_attention.2.in_proj_weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([552]) || layers.4.residual_group.blocks.2.attn.multi_scale_attention.2.in_proj_bias\n",
            " |  0.000 | -0.078 |  0.076 |  0.020 | torch.Size([184, 184]) || layers.4.residual_group.blocks.2.attn.multi_scale_attention.2.out_proj.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.4.residual_group.blocks.2.attn.multi_scale_attention.2.out_proj.bias\n",
            " | -0.000 | -0.087 |  0.093 |  0.020 | torch.Size([180, 552]) || layers.4.residual_group.blocks.2.attn.fuse_fc.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.2.attn.fuse_fc.bias\n",
            " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.2.norm2.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.2.norm2.bias\n",
            " |  0.000 | -0.082 |  0.082 |  0.020 | torch.Size([360, 180]) || layers.4.residual_group.blocks.2.mlp.fc1.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.4.residual_group.blocks.2.mlp.fc1.bias\n",
            " |  0.001 | -0.333 |  0.333 |  0.190 | torch.Size([360, 1, 3, 3]) || layers.4.residual_group.blocks.2.mlp.depthwise_conv.weight\n",
            " | -0.016 | -0.333 |  0.333 |  0.200 | torch.Size([360]) || layers.4.residual_group.blocks.2.mlp.depthwise_conv.bias\n",
            " |  0.000 | -0.081 |  0.090 |  0.020 | torch.Size([180, 360]) || layers.4.residual_group.blocks.2.mlp.fc2.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.2.mlp.fc2.bias\n",
            " | -15.972 | -100.000 |  0.000 | 36.635 | torch.Size([36, 64, 64]) || layers.4.residual_group.blocks.3.attn_mask\n",
            " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.3.norm1.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.3.norm1.bias\n",
            " | -0.000 | -0.079 |  0.077 |  0.020 | torch.Size([184, 180]) || layers.4.residual_group.blocks.3.attn.project_to_embed_dim.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.4.residual_group.blocks.3.attn.project_to_embed_dim.bias\n",
            " |  0.000 | -0.090 |  0.090 |  0.052 | torch.Size([552, 184]) || layers.4.residual_group.blocks.3.attn.multi_scale_attention.0.in_proj_weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([552]) || layers.4.residual_group.blocks.3.attn.multi_scale_attention.0.in_proj_bias\n",
            " |  0.000 | -0.080 |  0.087 |  0.020 | torch.Size([184, 184]) || layers.4.residual_group.blocks.3.attn.multi_scale_attention.0.out_proj.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.4.residual_group.blocks.3.attn.multi_scale_attention.0.out_proj.bias\n",
            " | -0.000 | -0.090 |  0.090 |  0.052 | torch.Size([552, 184]) || layers.4.residual_group.blocks.3.attn.multi_scale_attention.1.in_proj_weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([552]) || layers.4.residual_group.blocks.3.attn.multi_scale_attention.1.in_proj_bias\n",
            " | -0.000 | -0.085 |  0.080 |  0.020 | torch.Size([184, 184]) || layers.4.residual_group.blocks.3.attn.multi_scale_attention.1.out_proj.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.4.residual_group.blocks.3.attn.multi_scale_attention.1.out_proj.bias\n",
            " |  0.000 | -0.090 |  0.090 |  0.052 | torch.Size([552, 184]) || layers.4.residual_group.blocks.3.attn.multi_scale_attention.2.in_proj_weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([552]) || layers.4.residual_group.blocks.3.attn.multi_scale_attention.2.in_proj_bias\n",
            " | -0.000 | -0.083 |  0.081 |  0.020 | torch.Size([184, 184]) || layers.4.residual_group.blocks.3.attn.multi_scale_attention.2.out_proj.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.4.residual_group.blocks.3.attn.multi_scale_attention.2.out_proj.bias\n",
            " |  0.000 | -0.097 |  0.097 |  0.020 | torch.Size([180, 552]) || layers.4.residual_group.blocks.3.attn.fuse_fc.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.3.attn.fuse_fc.bias\n",
            " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.3.norm2.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.3.norm2.bias\n",
            " |  0.000 | -0.081 |  0.082 |  0.020 | torch.Size([360, 180]) || layers.4.residual_group.blocks.3.mlp.fc1.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.4.residual_group.blocks.3.mlp.fc1.bias\n",
            " |  0.001 | -0.333 |  0.333 |  0.190 | torch.Size([360, 1, 3, 3]) || layers.4.residual_group.blocks.3.mlp.depthwise_conv.weight\n",
            " | -0.009 | -0.332 |  0.330 |  0.198 | torch.Size([360]) || layers.4.residual_group.blocks.3.mlp.depthwise_conv.bias\n",
            " | -0.000 | -0.087 |  0.091 |  0.020 | torch.Size([180, 360]) || layers.4.residual_group.blocks.3.mlp.fc2.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.3.mlp.fc2.bias\n",
            " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.4.norm1.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.4.norm1.bias\n",
            " | -0.000 | -0.084 |  0.077 |  0.020 | torch.Size([184, 180]) || layers.4.residual_group.blocks.4.attn.project_to_embed_dim.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.4.residual_group.blocks.4.attn.project_to_embed_dim.bias\n",
            " |  0.000 | -0.090 |  0.090 |  0.052 | torch.Size([552, 184]) || layers.4.residual_group.blocks.4.attn.multi_scale_attention.0.in_proj_weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([552]) || layers.4.residual_group.blocks.4.attn.multi_scale_attention.0.in_proj_bias\n",
            " |  0.000 | -0.079 |  0.081 |  0.020 | torch.Size([184, 184]) || layers.4.residual_group.blocks.4.attn.multi_scale_attention.0.out_proj.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.4.residual_group.blocks.4.attn.multi_scale_attention.0.out_proj.bias\n",
            " |  0.000 | -0.090 |  0.090 |  0.052 | torch.Size([552, 184]) || layers.4.residual_group.blocks.4.attn.multi_scale_attention.1.in_proj_weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([552]) || layers.4.residual_group.blocks.4.attn.multi_scale_attention.1.in_proj_bias\n",
            " |  0.000 | -0.081 |  0.082 |  0.020 | torch.Size([184, 184]) || layers.4.residual_group.blocks.4.attn.multi_scale_attention.1.out_proj.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.4.residual_group.blocks.4.attn.multi_scale_attention.1.out_proj.bias\n",
            " |  0.000 | -0.090 |  0.090 |  0.052 | torch.Size([552, 184]) || layers.4.residual_group.blocks.4.attn.multi_scale_attention.2.in_proj_weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([552]) || layers.4.residual_group.blocks.4.attn.multi_scale_attention.2.in_proj_bias\n",
            " |  0.000 | -0.078 |  0.090 |  0.020 | torch.Size([184, 184]) || layers.4.residual_group.blocks.4.attn.multi_scale_attention.2.out_proj.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.4.residual_group.blocks.4.attn.multi_scale_attention.2.out_proj.bias\n",
            " |  0.000 | -0.086 |  0.093 |  0.020 | torch.Size([180, 552]) || layers.4.residual_group.blocks.4.attn.fuse_fc.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.4.attn.fuse_fc.bias\n",
            " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.4.norm2.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.4.norm2.bias\n",
            " | -0.000 | -0.090 |  0.081 |  0.020 | torch.Size([360, 180]) || layers.4.residual_group.blocks.4.mlp.fc1.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.4.residual_group.blocks.4.mlp.fc1.bias\n",
            " | -0.003 | -0.333 |  0.333 |  0.195 | torch.Size([360, 1, 3, 3]) || layers.4.residual_group.blocks.4.mlp.depthwise_conv.weight\n",
            " |  0.000 | -0.333 |  0.332 |  0.190 | torch.Size([360]) || layers.4.residual_group.blocks.4.mlp.depthwise_conv.bias\n",
            " | -0.000 | -0.078 |  0.084 |  0.020 | torch.Size([180, 360]) || layers.4.residual_group.blocks.4.mlp.fc2.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.4.mlp.fc2.bias\n",
            " | -15.972 | -100.000 |  0.000 | 36.635 | torch.Size([36, 64, 64]) || layers.4.residual_group.blocks.5.attn_mask\n",
            " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.5.norm1.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.5.norm1.bias\n",
            " | -0.000 | -0.085 |  0.080 |  0.020 | torch.Size([184, 180]) || layers.4.residual_group.blocks.5.attn.project_to_embed_dim.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.4.residual_group.blocks.5.attn.project_to_embed_dim.bias\n",
            " |  0.000 | -0.090 |  0.090 |  0.052 | torch.Size([552, 184]) || layers.4.residual_group.blocks.5.attn.multi_scale_attention.0.in_proj_weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([552]) || layers.4.residual_group.blocks.5.attn.multi_scale_attention.0.in_proj_bias\n",
            " | -0.000 | -0.086 |  0.084 |  0.020 | torch.Size([184, 184]) || layers.4.residual_group.blocks.5.attn.multi_scale_attention.0.out_proj.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.4.residual_group.blocks.5.attn.multi_scale_attention.0.out_proj.bias\n",
            " |  0.000 | -0.090 |  0.090 |  0.052 | torch.Size([552, 184]) || layers.4.residual_group.blocks.5.attn.multi_scale_attention.1.in_proj_weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([552]) || layers.4.residual_group.blocks.5.attn.multi_scale_attention.1.in_proj_bias\n",
            " | -0.000 | -0.083 |  0.078 |  0.020 | torch.Size([184, 184]) || layers.4.residual_group.blocks.5.attn.multi_scale_attention.1.out_proj.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.4.residual_group.blocks.5.attn.multi_scale_attention.1.out_proj.bias\n",
            " | -0.000 | -0.090 |  0.090 |  0.052 | torch.Size([552, 184]) || layers.4.residual_group.blocks.5.attn.multi_scale_attention.2.in_proj_weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([552]) || layers.4.residual_group.blocks.5.attn.multi_scale_attention.2.in_proj_bias\n",
            " | -0.000 | -0.087 |  0.075 |  0.020 | torch.Size([184, 184]) || layers.4.residual_group.blocks.5.attn.multi_scale_attention.2.out_proj.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.4.residual_group.blocks.5.attn.multi_scale_attention.2.out_proj.bias\n",
            " | -0.000 | -0.085 |  0.093 |  0.020 | torch.Size([180, 552]) || layers.4.residual_group.blocks.5.attn.fuse_fc.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.5.attn.fuse_fc.bias\n",
            " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.5.norm2.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.5.norm2.bias\n",
            " | -0.000 | -0.077 |  0.085 |  0.020 | torch.Size([360, 180]) || layers.4.residual_group.blocks.5.mlp.fc1.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.4.residual_group.blocks.5.mlp.fc1.bias\n",
            " |  0.001 | -0.333 |  0.333 |  0.193 | torch.Size([360, 1, 3, 3]) || layers.4.residual_group.blocks.5.mlp.depthwise_conv.weight\n",
            " | -0.014 | -0.333 |  0.333 |  0.189 | torch.Size([360]) || layers.4.residual_group.blocks.5.mlp.depthwise_conv.bias\n",
            " | -0.000 | -0.083 |  0.084 |  0.020 | torch.Size([180, 360]) || layers.4.residual_group.blocks.5.mlp.fc2.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.5.mlp.fc2.bias\n",
            " |  0.000 | -0.011 |  0.011 |  0.006 | torch.Size([1, 180, 7, 7]) || layers.4.attn_module.spatial_attention.0.weight\n",
            " | -0.010 | -0.010 | -0.010 |    nan | torch.Size([1]) || layers.4.attn_module.spatial_attention.0.bias\n",
            " |  0.001 | -0.075 |  0.075 |  0.042 | torch.Size([22, 180, 1, 1]) || layers.4.attn_module.channel_attention.1.weight\n",
            " |  0.001 | -0.071 |  0.074 |  0.047 | torch.Size([22]) || layers.4.attn_module.channel_attention.1.bias\n",
            " | -0.004 | -0.213 |  0.213 |  0.123 | torch.Size([180, 22, 1, 1]) || layers.4.attn_module.channel_attention.3.weight\n",
            " |  0.011 | -0.209 |  0.210 |  0.122 | torch.Size([180]) || layers.4.attn_module.channel_attention.3.bias\n",
            " | -0.000 | -0.025 |  0.025 |  0.014 | torch.Size([180, 180, 3, 3]) || layers.4.conv.weight\n",
            " | -0.001 | -0.024 |  0.025 |  0.014 | torch.Size([180]) || layers.4.conv.bias\n",
            " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.0.norm1.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.0.norm1.bias\n",
            " | -0.000 | -0.077 |  0.083 |  0.020 | torch.Size([184, 180]) || layers.5.residual_group.blocks.0.attn.project_to_embed_dim.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.5.residual_group.blocks.0.attn.project_to_embed_dim.bias\n",
            " |  0.000 | -0.090 |  0.090 |  0.052 | torch.Size([552, 184]) || layers.5.residual_group.blocks.0.attn.multi_scale_attention.0.in_proj_weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([552]) || layers.5.residual_group.blocks.0.attn.multi_scale_attention.0.in_proj_bias\n",
            " |  0.000 | -0.077 |  0.096 |  0.020 | torch.Size([184, 184]) || layers.5.residual_group.blocks.0.attn.multi_scale_attention.0.out_proj.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.5.residual_group.blocks.0.attn.multi_scale_attention.0.out_proj.bias\n",
            " | -0.000 | -0.090 |  0.090 |  0.052 | torch.Size([552, 184]) || layers.5.residual_group.blocks.0.attn.multi_scale_attention.1.in_proj_weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([552]) || layers.5.residual_group.blocks.0.attn.multi_scale_attention.1.in_proj_bias\n",
            " | -0.000 | -0.090 |  0.074 |  0.020 | torch.Size([184, 184]) || layers.5.residual_group.blocks.0.attn.multi_scale_attention.1.out_proj.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.5.residual_group.blocks.0.attn.multi_scale_attention.1.out_proj.bias\n",
            " | -0.000 | -0.090 |  0.090 |  0.052 | torch.Size([552, 184]) || layers.5.residual_group.blocks.0.attn.multi_scale_attention.2.in_proj_weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([552]) || layers.5.residual_group.blocks.0.attn.multi_scale_attention.2.in_proj_bias\n",
            " |  0.000 | -0.077 |  0.083 |  0.020 | torch.Size([184, 184]) || layers.5.residual_group.blocks.0.attn.multi_scale_attention.2.out_proj.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.5.residual_group.blocks.0.attn.multi_scale_attention.2.out_proj.bias\n",
            " |  0.000 | -0.100 |  0.087 |  0.020 | torch.Size([180, 552]) || layers.5.residual_group.blocks.0.attn.fuse_fc.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.0.attn.fuse_fc.bias\n",
            " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.0.norm2.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.0.norm2.bias\n",
            " | -0.000 | -0.083 |  0.084 |  0.020 | torch.Size([360, 180]) || layers.5.residual_group.blocks.0.mlp.fc1.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.5.residual_group.blocks.0.mlp.fc1.bias\n",
            " |  0.003 | -0.333 |  0.333 |  0.193 | torch.Size([360, 1, 3, 3]) || layers.5.residual_group.blocks.0.mlp.depthwise_conv.weight\n",
            " | -0.004 | -0.330 |  0.331 |  0.192 | torch.Size([360]) || layers.5.residual_group.blocks.0.mlp.depthwise_conv.bias\n",
            " | -0.000 | -0.089 |  0.093 |  0.020 | torch.Size([180, 360]) || layers.5.residual_group.blocks.0.mlp.fc2.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.0.mlp.fc2.bias\n",
            " | -15.972 | -100.000 |  0.000 | 36.635 | torch.Size([36, 64, 64]) || layers.5.residual_group.blocks.1.attn_mask\n",
            " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.1.norm1.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.1.norm1.bias\n",
            " |  0.000 | -0.078 |  0.078 |  0.020 | torch.Size([184, 180]) || layers.5.residual_group.blocks.1.attn.project_to_embed_dim.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.5.residual_group.blocks.1.attn.project_to_embed_dim.bias\n",
            " |  0.000 | -0.090 |  0.090 |  0.052 | torch.Size([552, 184]) || layers.5.residual_group.blocks.1.attn.multi_scale_attention.0.in_proj_weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([552]) || layers.5.residual_group.blocks.1.attn.multi_scale_attention.0.in_proj_bias\n",
            " | -0.000 | -0.090 |  0.075 |  0.020 | torch.Size([184, 184]) || layers.5.residual_group.blocks.1.attn.multi_scale_attention.0.out_proj.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.5.residual_group.blocks.1.attn.multi_scale_attention.0.out_proj.bias\n",
            " |  0.000 | -0.090 |  0.090 |  0.052 | torch.Size([552, 184]) || layers.5.residual_group.blocks.1.attn.multi_scale_attention.1.in_proj_weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([552]) || layers.5.residual_group.blocks.1.attn.multi_scale_attention.1.in_proj_bias\n",
            " | -0.000 | -0.079 |  0.081 |  0.020 | torch.Size([184, 184]) || layers.5.residual_group.blocks.1.attn.multi_scale_attention.1.out_proj.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.5.residual_group.blocks.1.attn.multi_scale_attention.1.out_proj.bias\n",
            " | -0.000 | -0.090 |  0.090 |  0.052 | torch.Size([552, 184]) || layers.5.residual_group.blocks.1.attn.multi_scale_attention.2.in_proj_weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([552]) || layers.5.residual_group.blocks.1.attn.multi_scale_attention.2.in_proj_bias\n",
            " | -0.000 | -0.090 |  0.089 |  0.020 | torch.Size([184, 184]) || layers.5.residual_group.blocks.1.attn.multi_scale_attention.2.out_proj.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.5.residual_group.blocks.1.attn.multi_scale_attention.2.out_proj.bias\n",
            " |  0.000 | -0.093 |  0.090 |  0.020 | torch.Size([180, 552]) || layers.5.residual_group.blocks.1.attn.fuse_fc.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.1.attn.fuse_fc.bias\n",
            " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.1.norm2.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.1.norm2.bias\n",
            " |  0.000 | -0.091 |  0.088 |  0.020 | torch.Size([360, 180]) || layers.5.residual_group.blocks.1.mlp.fc1.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.5.residual_group.blocks.1.mlp.fc1.bias\n",
            " | -0.004 | -0.333 |  0.333 |  0.192 | torch.Size([360, 1, 3, 3]) || layers.5.residual_group.blocks.1.mlp.depthwise_conv.weight\n",
            " |  0.007 | -0.329 |  0.333 |  0.194 | torch.Size([360]) || layers.5.residual_group.blocks.1.mlp.depthwise_conv.bias\n",
            " | -0.000 | -0.085 |  0.084 |  0.020 | torch.Size([180, 360]) || layers.5.residual_group.blocks.1.mlp.fc2.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.1.mlp.fc2.bias\n",
            " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.2.norm1.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.2.norm1.bias\n",
            " | -0.000 | -0.081 |  0.082 |  0.020 | torch.Size([184, 180]) || layers.5.residual_group.blocks.2.attn.project_to_embed_dim.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.5.residual_group.blocks.2.attn.project_to_embed_dim.bias\n",
            " | -0.000 | -0.090 |  0.090 |  0.052 | torch.Size([552, 184]) || layers.5.residual_group.blocks.2.attn.multi_scale_attention.0.in_proj_weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([552]) || layers.5.residual_group.blocks.2.attn.multi_scale_attention.0.in_proj_bias\n",
            " | -0.000 | -0.079 |  0.073 |  0.020 | torch.Size([184, 184]) || layers.5.residual_group.blocks.2.attn.multi_scale_attention.0.out_proj.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.5.residual_group.blocks.2.attn.multi_scale_attention.0.out_proj.bias\n",
            " | -0.000 | -0.090 |  0.090 |  0.052 | torch.Size([552, 184]) || layers.5.residual_group.blocks.2.attn.multi_scale_attention.1.in_proj_weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([552]) || layers.5.residual_group.blocks.2.attn.multi_scale_attention.1.in_proj_bias\n",
            " |  0.000 | -0.081 |  0.081 |  0.020 | torch.Size([184, 184]) || layers.5.residual_group.blocks.2.attn.multi_scale_attention.1.out_proj.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.5.residual_group.blocks.2.attn.multi_scale_attention.1.out_proj.bias\n",
            " |  0.000 | -0.090 |  0.090 |  0.052 | torch.Size([552, 184]) || layers.5.residual_group.blocks.2.attn.multi_scale_attention.2.in_proj_weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([552]) || layers.5.residual_group.blocks.2.attn.multi_scale_attention.2.in_proj_bias\n",
            " | -0.000 | -0.079 |  0.090 |  0.020 | torch.Size([184, 184]) || layers.5.residual_group.blocks.2.attn.multi_scale_attention.2.out_proj.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.5.residual_group.blocks.2.attn.multi_scale_attention.2.out_proj.bias\n",
            " |  0.000 | -0.088 |  0.091 |  0.020 | torch.Size([180, 552]) || layers.5.residual_group.blocks.2.attn.fuse_fc.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.2.attn.fuse_fc.bias\n",
            " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.2.norm2.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.2.norm2.bias\n",
            " |  0.000 | -0.082 |  0.083 |  0.020 | torch.Size([360, 180]) || layers.5.residual_group.blocks.2.mlp.fc1.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.5.residual_group.blocks.2.mlp.fc1.bias\n",
            " | -0.001 | -0.333 |  0.333 |  0.192 | torch.Size([360, 1, 3, 3]) || layers.5.residual_group.blocks.2.mlp.depthwise_conv.weight\n",
            " | -0.004 | -0.327 |  0.332 |  0.199 | torch.Size([360]) || layers.5.residual_group.blocks.2.mlp.depthwise_conv.bias\n",
            " |  0.000 | -0.089 |  0.084 |  0.020 | torch.Size([180, 360]) || layers.5.residual_group.blocks.2.mlp.fc2.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.2.mlp.fc2.bias\n",
            " | -15.972 | -100.000 |  0.000 | 36.635 | torch.Size([36, 64, 64]) || layers.5.residual_group.blocks.3.attn_mask\n",
            " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.3.norm1.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.3.norm1.bias\n",
            " |  0.000 | -0.079 |  0.094 |  0.020 | torch.Size([184, 180]) || layers.5.residual_group.blocks.3.attn.project_to_embed_dim.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.5.residual_group.blocks.3.attn.project_to_embed_dim.bias\n",
            " |  0.000 | -0.090 |  0.090 |  0.052 | torch.Size([552, 184]) || layers.5.residual_group.blocks.3.attn.multi_scale_attention.0.in_proj_weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([552]) || layers.5.residual_group.blocks.3.attn.multi_scale_attention.0.in_proj_bias\n",
            " |  0.000 | -0.085 |  0.078 |  0.020 | torch.Size([184, 184]) || layers.5.residual_group.blocks.3.attn.multi_scale_attention.0.out_proj.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.5.residual_group.blocks.3.attn.multi_scale_attention.0.out_proj.bias\n",
            " | -0.000 | -0.090 |  0.090 |  0.052 | torch.Size([552, 184]) || layers.5.residual_group.blocks.3.attn.multi_scale_attention.1.in_proj_weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([552]) || layers.5.residual_group.blocks.3.attn.multi_scale_attention.1.in_proj_bias\n",
            " |  0.000 | -0.081 |  0.078 |  0.020 | torch.Size([184, 184]) || layers.5.residual_group.blocks.3.attn.multi_scale_attention.1.out_proj.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.5.residual_group.blocks.3.attn.multi_scale_attention.1.out_proj.bias\n",
            " |  0.000 | -0.090 |  0.090 |  0.052 | torch.Size([552, 184]) || layers.5.residual_group.blocks.3.attn.multi_scale_attention.2.in_proj_weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([552]) || layers.5.residual_group.blocks.3.attn.multi_scale_attention.2.in_proj_bias\n",
            " |  0.000 | -0.088 |  0.082 |  0.020 | torch.Size([184, 184]) || layers.5.residual_group.blocks.3.attn.multi_scale_attention.2.out_proj.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.5.residual_group.blocks.3.attn.multi_scale_attention.2.out_proj.bias\n",
            " | -0.000 | -0.087 |  0.085 |  0.020 | torch.Size([180, 552]) || layers.5.residual_group.blocks.3.attn.fuse_fc.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.3.attn.fuse_fc.bias\n",
            " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.3.norm2.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.3.norm2.bias\n",
            " | -0.000 | -0.085 |  0.076 |  0.020 | torch.Size([360, 180]) || layers.5.residual_group.blocks.3.mlp.fc1.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.5.residual_group.blocks.3.mlp.fc1.bias\n",
            " |  0.000 | -0.333 |  0.333 |  0.193 | torch.Size([360, 1, 3, 3]) || layers.5.residual_group.blocks.3.mlp.depthwise_conv.weight\n",
            " |  0.005 | -0.332 |  0.332 |  0.191 | torch.Size([360]) || layers.5.residual_group.blocks.3.mlp.depthwise_conv.bias\n",
            " |  0.000 | -0.092 |  0.088 |  0.020 | torch.Size([180, 360]) || layers.5.residual_group.blocks.3.mlp.fc2.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.3.mlp.fc2.bias\n",
            " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.4.norm1.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.4.norm1.bias\n",
            " |  0.000 | -0.085 |  0.080 |  0.020 | torch.Size([184, 180]) || layers.5.residual_group.blocks.4.attn.project_to_embed_dim.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.5.residual_group.blocks.4.attn.project_to_embed_dim.bias\n",
            " | -0.000 | -0.090 |  0.090 |  0.052 | torch.Size([552, 184]) || layers.5.residual_group.blocks.4.attn.multi_scale_attention.0.in_proj_weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([552]) || layers.5.residual_group.blocks.4.attn.multi_scale_attention.0.in_proj_bias\n",
            " |  0.000 | -0.083 |  0.082 |  0.020 | torch.Size([184, 184]) || layers.5.residual_group.blocks.4.attn.multi_scale_attention.0.out_proj.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.5.residual_group.blocks.4.attn.multi_scale_attention.0.out_proj.bias\n",
            " |  0.000 | -0.090 |  0.090 |  0.052 | torch.Size([552, 184]) || layers.5.residual_group.blocks.4.attn.multi_scale_attention.1.in_proj_weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([552]) || layers.5.residual_group.blocks.4.attn.multi_scale_attention.1.in_proj_bias\n",
            " | -0.000 | -0.078 |  0.077 |  0.020 | torch.Size([184, 184]) || layers.5.residual_group.blocks.4.attn.multi_scale_attention.1.out_proj.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.5.residual_group.blocks.4.attn.multi_scale_attention.1.out_proj.bias\n",
            " |  0.000 | -0.090 |  0.090 |  0.052 | torch.Size([552, 184]) || layers.5.residual_group.blocks.4.attn.multi_scale_attention.2.in_proj_weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([552]) || layers.5.residual_group.blocks.4.attn.multi_scale_attention.2.in_proj_bias\n",
            " | -0.000 | -0.075 |  0.080 |  0.020 | torch.Size([184, 184]) || layers.5.residual_group.blocks.4.attn.multi_scale_attention.2.out_proj.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.5.residual_group.blocks.4.attn.multi_scale_attention.2.out_proj.bias\n",
            " | -0.000 | -0.087 |  0.097 |  0.020 | torch.Size([180, 552]) || layers.5.residual_group.blocks.4.attn.fuse_fc.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.4.attn.fuse_fc.bias\n",
            " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.4.norm2.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.4.norm2.bias\n",
            " | -0.000 | -0.079 |  0.089 |  0.020 | torch.Size([360, 180]) || layers.5.residual_group.blocks.4.mlp.fc1.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.5.residual_group.blocks.4.mlp.fc1.bias\n",
            " | -0.002 | -0.333 |  0.333 |  0.195 | torch.Size([360, 1, 3, 3]) || layers.5.residual_group.blocks.4.mlp.depthwise_conv.weight\n",
            " | -0.004 | -0.331 |  0.333 |  0.195 | torch.Size([360]) || layers.5.residual_group.blocks.4.mlp.depthwise_conv.bias\n",
            " |  0.000 | -0.084 |  0.087 |  0.020 | torch.Size([180, 360]) || layers.5.residual_group.blocks.4.mlp.fc2.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.4.mlp.fc2.bias\n",
            " | -15.972 | -100.000 |  0.000 | 36.635 | torch.Size([36, 64, 64]) || layers.5.residual_group.blocks.5.attn_mask\n",
            " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.5.norm1.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.5.norm1.bias\n",
            " | -0.000 | -0.076 |  0.097 |  0.020 | torch.Size([184, 180]) || layers.5.residual_group.blocks.5.attn.project_to_embed_dim.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.5.residual_group.blocks.5.attn.project_to_embed_dim.bias\n",
            " | -0.000 | -0.090 |  0.090 |  0.052 | torch.Size([552, 184]) || layers.5.residual_group.blocks.5.attn.multi_scale_attention.0.in_proj_weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([552]) || layers.5.residual_group.blocks.5.attn.multi_scale_attention.0.in_proj_bias\n",
            " |  0.000 | -0.086 |  0.084 |  0.020 | torch.Size([184, 184]) || layers.5.residual_group.blocks.5.attn.multi_scale_attention.0.out_proj.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.5.residual_group.blocks.5.attn.multi_scale_attention.0.out_proj.bias\n",
            " |  0.000 | -0.090 |  0.090 |  0.052 | torch.Size([552, 184]) || layers.5.residual_group.blocks.5.attn.multi_scale_attention.1.in_proj_weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([552]) || layers.5.residual_group.blocks.5.attn.multi_scale_attention.1.in_proj_bias\n",
            " |  0.000 | -0.078 |  0.085 |  0.020 | torch.Size([184, 184]) || layers.5.residual_group.blocks.5.attn.multi_scale_attention.1.out_proj.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.5.residual_group.blocks.5.attn.multi_scale_attention.1.out_proj.bias\n",
            " | -0.000 | -0.090 |  0.090 |  0.052 | torch.Size([552, 184]) || layers.5.residual_group.blocks.5.attn.multi_scale_attention.2.in_proj_weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([552]) || layers.5.residual_group.blocks.5.attn.multi_scale_attention.2.in_proj_bias\n",
            " | -0.000 | -0.078 |  0.092 |  0.020 | torch.Size([184, 184]) || layers.5.residual_group.blocks.5.attn.multi_scale_attention.2.out_proj.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([184]) || layers.5.residual_group.blocks.5.attn.multi_scale_attention.2.out_proj.bias\n",
            " |  0.000 | -0.079 |  0.092 |  0.020 | torch.Size([180, 552]) || layers.5.residual_group.blocks.5.attn.fuse_fc.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.5.attn.fuse_fc.bias\n",
            " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.5.norm2.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.5.norm2.bias\n",
            " | -0.000 | -0.083 |  0.084 |  0.020 | torch.Size([360, 180]) || layers.5.residual_group.blocks.5.mlp.fc1.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.5.residual_group.blocks.5.mlp.fc1.bias\n",
            " | -0.000 | -0.333 |  0.333 |  0.193 | torch.Size([360, 1, 3, 3]) || layers.5.residual_group.blocks.5.mlp.depthwise_conv.weight\n",
            " | -0.004 | -0.332 |  0.328 |  0.194 | torch.Size([360]) || layers.5.residual_group.blocks.5.mlp.depthwise_conv.bias\n",
            " | -0.000 | -2.000 |  0.083 |  0.022 | torch.Size([180, 360]) || layers.5.residual_group.blocks.5.mlp.fc2.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.5.mlp.fc2.bias\n",
            " |  0.000 | -0.011 |  0.011 |  0.006 | torch.Size([1, 180, 7, 7]) || layers.5.attn_module.spatial_attention.0.weight\n",
            " |  0.001 |  0.001 |  0.001 |    nan | torch.Size([1]) || layers.5.attn_module.spatial_attention.0.bias\n",
            " | -0.001 | -0.075 |  0.074 |  0.043 | torch.Size([22, 180, 1, 1]) || layers.5.attn_module.channel_attention.1.weight\n",
            " | -0.012 | -0.067 |  0.060 |  0.039 | torch.Size([22]) || layers.5.attn_module.channel_attention.1.bias\n",
            " |  0.002 | -0.213 |  0.213 |  0.124 | torch.Size([180, 22, 1, 1]) || layers.5.attn_module.channel_attention.3.weight\n",
            " | -0.010 | -0.212 |  0.211 |  0.124 | torch.Size([180]) || layers.5.attn_module.channel_attention.3.bias\n",
            " |  0.000 | -0.025 |  0.025 |  0.014 | torch.Size([180, 180, 3, 3]) || layers.5.conv.weight\n",
            " |  0.002 | -0.024 |  0.025 |  0.014 | torch.Size([180]) || layers.5.conv.bias\n",
            " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || norm.weight\n",
            " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || norm.bias\n",
            " | -0.000 | -0.025 |  0.025 |  0.014 | torch.Size([180, 180, 3, 3]) || conv_after_body.weight\n",
            " |  0.000 | -0.025 |  0.024 |  0.014 | torch.Size([180]) || conv_after_body.bias\n",
            " | -0.000 | -0.025 |  0.025 |  0.014 | torch.Size([64, 180, 3, 3]) || conv_before_upsample.0.weight\n",
            " | -0.002 | -0.024 |  0.024 |  0.014 | torch.Size([64]) || conv_before_upsample.0.bias\n",
            " |  0.000 | -0.042 |  0.042 |  0.024 | torch.Size([256, 64, 3, 3]) || upsample.0.weight\n",
            " | -0.002 | -0.042 |  0.042 |  0.025 | torch.Size([256]) || upsample.0.bias\n",
            " |  0.001 | -0.042 |  0.041 |  0.024 | torch.Size([3, 64, 3, 3]) || conv_last.weight\n",
            " | -0.004 | -0.029 |  0.022 |  0.025 | torch.Size([3]) || conv_last.bias\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:240: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:595: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  _warn_get_lr_called_within_step(self)\n",
            "24-11-19 13:31:39.492 : <epoch:  0, iter:     200, lr:2.000e-04> G_loss: 5.764e-02 \n",
            "24-11-19 13:36:01.445 : <epoch:  1, iter:     400, lr:2.000e-04> G_loss: 5.239e-02 \n",
            "24-11-19 13:40:22.527 : <epoch:  2, iter:     600, lr:2.000e-04> G_loss: 3.575e-02 \n",
            "24-11-19 13:44:44.497 : <epoch:  3, iter:     800, lr:2.000e-04> G_loss: 5.167e-02 \n",
            "24-11-19 13:49:06.114 : <epoch:  4, iter:   1,000, lr:2.000e-04> G_loss: 2.717e-02 \n",
            "24-11-19 13:53:27.364 : <epoch:  5, iter:   1,200, lr:2.000e-04> G_loss: 3.476e-02 \n",
            "24-11-19 13:57:49.104 : <epoch:  6, iter:   1,400, lr:2.000e-04> G_loss: 1.683e-02 \n",
            "24-11-19 14:02:11.428 : <epoch:  7, iter:   1,600, lr:2.000e-04> G_loss: 4.658e-02 \n",
            "24-11-19 14:06:35.367 : <epoch:  8, iter:   1,800, lr:2.000e-04> G_loss: 1.827e-02 \n",
            "24-11-19 14:10:57.704 : <epoch:  9, iter:   2,000, lr:2.000e-04> G_loss: 2.526e-02 \n",
            "24-11-19 14:15:20.746 : <epoch: 10, iter:   2,200, lr:2.000e-04> G_loss: 2.200e-02 \n",
            "24-11-19 14:19:42.218 : <epoch: 11, iter:   2,400, lr:2.000e-04> G_loss: 2.121e-02 \n",
            "24-11-19 14:24:04.122 : <epoch: 12, iter:   2,600, lr:2.000e-04> G_loss: 2.137e-02 \n",
            "24-11-19 14:28:25.658 : <epoch: 13, iter:   2,800, lr:2.000e-04> G_loss: 1.439e-02 \n",
            "24-11-19 14:32:47.369 : <epoch: 14, iter:   3,000, lr:2.000e-04> G_loss: 2.016e-02 \n",
            "24-11-19 14:37:08.483 : <epoch: 15, iter:   3,200, lr:2.000e-04> G_loss: 2.614e-02 \n",
            "24-11-19 14:41:29.927 : <epoch: 16, iter:   3,400, lr:2.000e-04> G_loss: 3.042e-02 \n",
            "24-11-19 14:45:51.430 : <epoch: 17, iter:   3,600, lr:2.000e-04> G_loss: 2.784e-02 \n"
          ]
        }
      ]
    }
  ]
}